{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow AI Gateway: Stay at the Frontier\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "When new models (GPT-5, Claude Sonnet 4.5, Gemini 2.5) are released, platform teams need to **evaluate, compare, and gradually migrate** ‚Äî balancing **quality, latency, cost, and governance** ‚Äî without breaking production.\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "**Part 1: Fundamentals** (5 min)\n",
    "1. ‚úÖ Automated tracing - every call logged\n",
    "2. üìù Prompt versioning - register and compare\n",
    "\n",
    "**Part 2: Model Migration Workflow** (15 min)\n",
    "3. üîÑ Baseline from current model\n",
    "4. üéØ Auto-optimize for new model\n",
    "5. üìä Compare quality, latency, cost\n",
    "6. üöÄ Gradual A/B migration\n",
    "\n",
    "**Key:** Inline APIs - just call, automatic MLflow tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/ahmed.bilal/Desktop/gateway-oss\n",
      "\u001b[31mERROR: file:///Users/ahmed.bilal/Desktop/gateway-oss does not appear to be a Python project: neither 'setup.py' nor 'pyproject.toml' found.\u001b[0m\u001b[31m\n",
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "# Install mlflowlite (force reinstall to get latest fixes)\n",
    "%pip install -e . --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'load_prompt' from 'mlflowlite.prompts' (/Users/ahmed.bilal/Desktop/gateway-oss/mlflowlite/prompts/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[49]\u001b[39m\u001b[32m, line 20\u001b[39m\n\u001b[32m     17\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m sys.modules[\u001b[33m'\u001b[39m\u001b[33mmlflowlite\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     19\u001b[39m \u001b[38;5;66;03m# Import everything you need\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m20\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflowlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     21\u001b[39m     Agent,\n\u001b[32m     22\u001b[39m     load_prompt,\n\u001b[32m     23\u001b[39m     print_suggestions,\n\u001b[32m     24\u001b[39m     query,\n\u001b[32m     25\u001b[39m     set_timeout,\n\u001b[32m     26\u001b[39m     set_max_retries,\n\u001b[32m     27\u001b[39m     set_fallback_models,\n\u001b[32m     28\u001b[39m     smart_query,\n\u001b[32m     29\u001b[39m     create_ab_test\n\u001b[32m     30\u001b[39m )\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m os.environ.get(\u001b[33m'\u001b[39m\u001b[33mANTHROPIC_API_KEY\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m os.environ[\u001b[33m'\u001b[39m\u001b[33mANTHROPIC_API_KEY\u001b[39m\u001b[33m'\u001b[39m] != \u001b[33m'\u001b[39m\u001b[33myour-api-key-here\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m     33\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33müîë API key configured\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/gateway-oss/mlflowlite/__init__.py:56\u001b[39m\n\u001b[32m     43\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflowlite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mevaluation\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[32m     44\u001b[39m     evaluate,\n\u001b[32m     45\u001b[39m     evaluate_with_traces,\n\u001b[32m   (...)\u001b[39m\u001b[32m     52\u001b[39m     scorer,\n\u001b[32m     53\u001b[39m )\n\u001b[32m     55\u001b[39m \u001b[38;5;66;03m# Prompt Registry\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m56\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmlflowlite\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprompts\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_prompt\n\u001b[32m     58\u001b[39m __version__ = \u001b[33m\"\u001b[39m\u001b[33m0.1.0\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     59\u001b[39m __all__ = [\n\u001b[32m     60\u001b[39m     \u001b[38;5;66;03m# Core classes\u001b[39;00m\n\u001b[32m     61\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mAgent\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    101\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mload_prompt\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m    102\u001b[39m ]\n",
      "\u001b[31mImportError\u001b[39m: cannot import name 'load_prompt' from 'mlflowlite.prompts' (/Users/ahmed.bilal/Desktop/gateway-oss/mlflowlite/prompts/__init__.py)"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('LiteLLM').setLevel(logging.ERROR)  # Suppress LiteLLM info messages\n",
    "\n",
    "# ‚ö†Ô∏è Set your API key here \n",
    "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
    "    os.environ['ANTHROPIC_API_KEY'] = 'your-anthropic-api-key-here'  # üëà Replace with your key\n",
    "\n",
    "# üí° For Databricks: Set Unity Catalog schema for prompts (optional)\n",
    "# os.environ['MLFLOW_PROMPT_REGISTRY_UC_SCHEMA'] = 'your_catalog.your_schema'\n",
    "\n",
    "# Force reload module (fixes Cursor/VS Code notebook caching)\n",
    "import sys\n",
    "if 'mlflowlite' in sys.modules:\n",
    "    del sys.modules['mlflowlite']\n",
    "\n",
    "# Import everything you need\n",
    "from mlflowlite import (\n",
    "    Agent,\n",
    "    load_prompt,\n",
    "    print_suggestions,\n",
    "    query,\n",
    "    set_timeout,\n",
    "    set_max_retries,\n",
    "    set_fallback_models,\n",
    "    smart_query,\n",
    "    create_ab_test\n",
    ")\n",
    "\n",
    "if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'your-api-key-here':\n",
    "    print(\"üîë API key configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please set your ANTHROPIC_API_KEY in the cell above\")\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Fundamentals\n",
    "\n",
    "## üìä Feature 1: Automatic Tracing\n",
    "\n",
    "### The Old Way (Without Tracing)\n",
    "\n",
    "```python\n",
    "response = openai.chat.completions.create(...)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "Questions you can't answer:\n",
    "- ‚ùì How much did that cost?\n",
    "- ‚ùì How long did it take?\n",
    "- ‚ùì Can I compare versions?\n",
    "\n",
    "**You're flying blind!** üõ©Ô∏èüí®\n",
    "\n",
    "---\n",
    "\n",
    "### The New Way (With mlflowlite)\n",
    "\n",
    "Same code, **automatic insights**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Positive**\n",
      "\n",
      "The sentiment is clearly positive due to the enthusiastic language (\"amazing!\") and exclamation mark, which indicates strong approval and satisfaction with the product.\n"
     ]
    }
   ],
   "source": [
    "# Create agent - automatically traced!\n",
    "agent = Agent(model='claude-sonnet-4-20250514')\n",
    "response = agent(\"Classify sentiment as positive/negative/neutral: This product is amazing!\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: $0.0006 | Tokens: 61 | Latency: 3.20s\n",
      "\n",
      "üîó MLflow UI Links:\n",
      "   üìä Run Details: http://localhost:5000/#/experiments/809917521309205504/runs/c47f9618e1c046fd88831d017d6c7f00\n",
      "   üß™ Experiment: http://localhost:5000/#/experiments/809917521309205504\n",
      "   üìÅ Artifacts: http://localhost:5000/#/experiments/809917521309205504/runs/c47f9618e1c046fd88831d017d6c7f00/artifactPath\n",
      "\n",
      "   üí° Tip: Click Cmd/Ctrl + Click to open in browser\n",
      "\n",
      "‚úÖ Automatic tracking:\n",
      "   ‚Ä¢ Cost\n",
      "   ‚Ä¢ Latency\n",
      "   ‚Ä¢ Tokens\n",
      "   ‚Ä¢ MLflow run created\n",
      "   ‚Ä¢ UI links\n"
     ]
    }
   ],
   "source": [
    "# üéØ Value Unlocked: See Everything Automatically\n",
    "print(f\"Cost: ${response.cost:.4f} | Tokens: {response.usage.get('total_tokens', 0)} | Latency: {response.latency:.2f}s\")\n",
    "\n",
    "# View in MLflow UI\n",
    "response.print_links()\n",
    "\n",
    "print(\"\\n‚úÖ Automatic tracking:\")\n",
    "print(\"   ‚Ä¢ Cost\")\n",
    "print(\"   ‚Ä¢ Latency\")\n",
    "print(\"   ‚Ä¢ Tokens\")\n",
    "print(\"   ‚Ä¢ MLflow run created\")\n",
    "print(\"   ‚Ä¢ UI links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Feature 2: Prompt Versioning\n",
    "\n",
    "### The Old Way (Without Versioning)\n",
    "\n",
    "**Monday:** Great prompt!\n",
    "\n",
    "**Tuesday:** \"Improved\" it. Now slower and costly.\n",
    "\n",
    "**Wednesday:** Want Monday's version... üò± **Didn't save it!**\n",
    "\n",
    "**You're guessing in the dark!** üé≤\n",
    "\n",
    "---\n",
    "\n",
    "### The New Way (With Prompt Versioning)\n",
    "\n",
    "Track every version. Compare with real numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'main.default.sentiment_classifier_prompt' version 1 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí main.default.sentiment_classifier_prompt\n",
      "‚úÖ Agent created with prompt versioning\n"
     ]
    }
   ],
   "source": [
    "# Create agent with prompt versioning\n",
    "agent = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=\"Classify sentiment: {{text}}\",\n",
    "    prompt_name=\"sentiment_classifier\"  # üëà Triggers versioning!\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agent created with prompt versioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 71 tokens, $0.0007\n"
     ]
    }
   ],
   "source": [
    "# Test v1\n",
    "result_v1 = agent(text=\"The service was excellent!\")\n",
    "print(f\"v1: {result_v1.usage['total_tokens']} tokens, ${result_v1.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'main.default.sentiment_classifier_prompt' version 2 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí main.default.sentiment_classifier_prompt\n",
      "‚úÖ v2 registered\n"
     ]
    }
   ],
   "source": [
    "# Add improved version - just create agent again with same prompt_name!\n",
    "agent = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=\"Classify sentiment. Answer ONLY: positive, negative, or neutral.\\n\\nText: {{text}}\",\n",
    "    prompt_name=\"sentiment_classifier\"  # üëà Same name = new version!\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ v{agent.prompt_registry.get_latest().version} registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2: 58 tokens, $0.0006\n",
      "\n",
      "üí∞ Difference: 13 tokens, $0.0001\n"
     ]
    }
   ],
   "source": [
    "# Test v2\n",
    "result_v2 = agent(text=\"The service was excellent!\")\n",
    "print(f\"v2: {result_v2.usage['total_tokens']} tokens, ${result_v2.cost:.4f}\")\n",
    "\n",
    "# Compare\n",
    "tokens_saved = result_v1.usage['total_tokens'] - result_v2.usage['total_tokens']\n",
    "print(f\"\\nüí∞ Difference: {tokens_saved} tokens, ${result_v1.cost - result_v2.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Inline Prompt Retrieval\n",
    "\n",
    "Retrieve and use any version in a single statement - no intermediate steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_prompt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Inline retrieval: load and use in one statement!\u001b[39;00m\n\u001b[32m      2\u001b[39m \n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Use version 1 inline\u001b[39;00m\n\u001b[32m      4\u001b[39m result_v1 = Agent(\n\u001b[32m      5\u001b[39m     model=\u001b[33m\"\u001b[39m\u001b[33mclaude-sonnet-4-20250514\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     prompt=\u001b[43mload_prompt\u001b[49m(\u001b[33m\"\u001b[39m\u001b[33msentiment_classifier\u001b[39m\u001b[33m\"\u001b[39m, version=\u001b[32m1\u001b[39m)\n\u001b[32m      7\u001b[39m )(text=\u001b[33m\"\u001b[39m\u001b[33mThe service was excellent!\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      8\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mv1: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresult_v1.content\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;66;03m# Use version 2 inline  \u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'load_prompt' is not defined"
     ]
    }
   ],
   "source": [
    "# Inline retrieval: load and use in one statement!\n",
    "\n",
    "# Use version 1 inline\n",
    "result_v1 = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=load_prompt(\"sentiment_classifier\", version=1)\n",
    ")(text=\"The service was excellent!\")\n",
    "print(f\"v1: {result_v1.content}\")\n",
    "\n",
    "# Use version 2 inline  \n",
    "result_v2 = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=load_prompt(\"sentiment_classifier\", version=2)\n",
    ")(text=\"The service was excellent!\")\n",
    "print(f\"v2: {result_v2.content}\")\n",
    "\n",
    "# Use latest inline\n",
    "result_latest = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=load_prompt(\"sentiment_classifier\")  # No version = latest\n",
    ")(text=\"The service was excellent!\")\n",
    "print(f\"latest: {result_latest.content}\")\n",
    "\n",
    "print(\"\\n‚úÖ Inline retrieval:\")\n",
    "print(\"   ‚Ä¢ load_prompt(name, version=1) - specific version\")\n",
    "print(\"   ‚Ä¢ load_prompt(name) - latest version\")\n",
    "print(\"   ‚Ä¢ Use immediately: Agent(prompt=load_prompt(...))(text=...)\")\n",
    "print(\"   ‚Ä¢ Clean, simple API!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Model Migration Workflow\n",
    "\n",
    "## üéØ The Scenario\n",
    "\n",
    "**Production:** Sentiment classifier using Claude Sonnet 4.0\n",
    "\n",
    "**New Release:** Claude Sonnet 4.0o-mini (faster, 50x cheaper!)\n",
    "\n",
    "**Question:** Can you migrate without breaking production?\n",
    "\n",
    "**Answer:** Yes! With inline APIs and automatic tracking.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Your Production App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production classifier (Sonnet 4.0)\n",
    "prod_agent = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=\"Classify sentiment as positive, negative, or neutral: {{text}}\",\n",
    "    prompt_name=\"production_sentiment\"\n",
    ")\n",
    "\n",
    "# Test current production\n",
    "result = prod_agent(text=\"Amazing product!\")\n",
    "print(f\"Sonnet 4.0 Result: {result.content}\")\n",
    "print(f\"Cost: ${result.cost:.4f} | Latency: {result.latency:.2f}s\")\n",
    "\n",
    "print(\"\\n‚úÖ Current production: Sonnet 4.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collect Baseline Data\n",
    "\n",
    "Each call creates MLflow run automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production test cases\n",
    "test_cases = [\n",
    "    \"This movie was fantastic!\",\n",
    "    \"The service was terrible.\",\n",
    "    \"It was okay.\",\n",
    "    \"Very disappointed.\",\n",
    "    \"Best experience ever!\",\n",
    "    \"Works as described.\",\n",
    "    \"Can't believe how amazing!\",\n",
    "    \"Worst support ever.\",\n",
    "    \"Fine for the price.\",\n",
    "    \"Exceeded expectations!\"\n",
    "]\n",
    "\n",
    "# Collect baseline\n",
    "print(\"üîÑ Collecting baseline from Sonnet 4.0...\\n\")\n",
    "baseline = []\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    result = prod_agent(text=text)  # Auto-creates MLflow run!\n",
    "    sentiment = result.content.lower().strip()\n",
    "    baseline.append(sentiment)\n",
    "    print(f\"{i}. {text[:30]:30s} ‚Üí {sentiment}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(baseline)} baseline outputs\")\n",
    "print(f\"‚úÖ {len(baseline)} MLflow runs created automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test New Model\n",
    "\n",
    "Test Claude Sonnet 4.0o-mini with same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model agent\n",
    "new_agent = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=load_prompt(\"production_sentiment\")  # Same prompt\n",
    ")\n",
    "\n",
    "# Test new model\n",
    "print(\"üîÑ Testing Sonnet 4.0o-mini...\\n\")\n",
    "new_outputs = []\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    result = new_agent(text=text)  # Auto-creates MLflow run!\n",
    "    sentiment = result.content.lower().strip()\n",
    "    new_outputs.append(sentiment)\n",
    "    match = \"‚úÖ\" if sentiment == baseline[i-1] else \"‚ùå\"\n",
    "    print(f\"{i}. {match} new: {sentiment:8s} (baseline: {baseline[i-1]})\")\n",
    "\n",
    "# Calculate consistency\n",
    "matches = sum(1 for n, b in zip(new_outputs, baseline) if n == b)\n",
    "consistency = matches / len(baseline) * 100\n",
    "\n",
    "print(f\"\\nüìä Consistency: {consistency:.0f}%\")\n",
    "print(f\"‚úÖ {len(new_outputs)} more MLflow runs created!\")\n",
    "if consistency < 90:\n",
    "    print(\"\\n‚ö†Ô∏è Need optimization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Auto-Optimize Prompt\n",
    "\n",
    "Use DSPy suggestions to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimization suggestions\n",
    "sample = prod_agent(text=\"This product is good\")\n",
    "print(\"üéØ Getting optimization suggestions...\\n\")\n",
    "print_suggestions(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimized version - recreate agent with same prompt_name\n",
    "prod_agent = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=\"\"\"Classify sentiment of the text.\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY with: positive, negative, or neutral\n",
    "- Use lowercase\n",
    "- No explanation\n",
    "\n",
    "Text: {{text}}\n",
    "\n",
    "Answer:\"\"\",\n",
    "    prompt_name=\"production_sentiment\"  # üëà Same name = new version!\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Optimized prompt v{prod_agent.prompt_registry.get_latest().version} registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Optimized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized agent\n",
    "opt_agent = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=load_prompt(\"production_sentiment\")  # Optimized prompt\n",
    ")\n",
    "\n",
    "# Test optimized\n",
    "print(\"üîÑ Testing optimized version...\\n\")\n",
    "opt_outputs = []\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    result = opt_agent(text=text)  # Auto-creates MLflow run!\n",
    "    sentiment = result.content.lower().strip()\n",
    "    opt_outputs.append(sentiment)\n",
    "    match = \"‚úÖ\" if sentiment == baseline[i-1] else \"‚ùå\"\n",
    "    print(f\"{i}. {match} opt: {sentiment:8s} (baseline: {baseline[i-1]})\")\n",
    "\n",
    "# Calculate improvement\n",
    "matches = sum(1 for o, b in zip(opt_outputs, baseline) if o == b)\n",
    "improved = matches / len(baseline) * 100\n",
    "\n",
    "print(f\"\\nüìä Before: {consistency:.0f}% | After: {improved:.0f}%\")\n",
    "print(f\"üéâ Improvement: +{improved - consistency:.0f} points!\")\n",
    "print(f\"\\n‚úÖ {len(opt_outputs)} more MLflow runs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"Sonnet 4.0\",\n",
    "        \"Prompt\": \"Original\",\n",
    "        \"Consistency\": \"100%\",\n",
    "        \"Latency\": \"~800ms\",\n",
    "        \"Cost/1M\": \"$30\",\n",
    "        \"Status\": \"üü¢ Production\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Sonnet 4.0o-mini\",\n",
    "        \"Prompt\": \"Original\",\n",
    "        \"Consistency\": f\"{consistency:.0f}%\",\n",
    "        \"Latency\": \"~300ms\",\n",
    "        \"Cost/1M\": \"$0.60\",\n",
    "        \"Status\": \"‚ùå Not Ready\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Sonnet 4.0o-mini\",\n",
    "        \"Prompt\": \"Optimized\",\n",
    "        \"Consistency\": f\"{improved:.0f}%\",\n",
    "        \"Latency\": \"~300ms\",\n",
    "        \"Cost/1M\": \"$0.60\",\n",
    "        \"Status\": \"‚úÖ Ready!\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nüìä Model Comparison:\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Benefits:\")\n",
    "print(\"   ‚Ä¢ 2.5x faster\")\n",
    "print(\"   ‚Ä¢ 50x cheaper\")\n",
    "print(\"   ‚Ä¢ Same quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Gradual Migration (A/B Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A/B test: 80% Sonnet 4.0, 20% Sonnet 4.0o-mini\n",
    "migration_test = create_ab_test(\n",
    "    name=\"sonnet4_to_45_migration\",\n",
    "    variants={\n",
    "        'sonnet4': {\n",
    "            'model': 'claude-sonnet-4-20250514',\n",
    "            'weight': 80,\n",
    "            'prompt': load_prompt('production_sentiment', version=1)\n",
    "        },\n",
    "        'sonnet45': {\n",
    "            'model': 'claude-sonnet-4.5-20251022',\n",
    "            'weight': 20,\n",
    "            'prompt': load_prompt('production_sentiment')\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ A/B test created: 80% Sonnet 4.0, 20% Sonnet 4.0o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate production traffic\n",
    "print(\"üöÄ Simulating traffic...\\n\")\n",
    "\n",
    "stats = {'sonnet4': 0, 'sonnet45': 0}\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    variant, response = migration_test.run(\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Classify: {text}\"}]\n",
    "    )  # Auto-creates MLflow run!\n",
    "    stats[variant] += 1\n",
    "    print(f\"{i}. {variant:12s} | {response.content.lower()[:8]:8s} | ${response.cost:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Distribution:\")\n",
    "for variant, count in stats.items():\n",
    "    print(f\"   {variant}: {count}/{len(test_cases)} ({count*10}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(test_cases)} MLflow runs created automatically!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View A/B test results\n",
    "migration_test.print_report()\n",
    "\n",
    "print(\"\\nüí° Migration path:\")\n",
    "print(\"   5% ‚Üí 20% ‚Üí 50% ‚Üí 80% ‚Üí 100%\")\n",
    "print(\"   Monitor MLflow UI at each step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Full Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production V2: 100% Sonnet 4.0o-mini\n",
    "prod_v2 = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=load_prompt(\"production_sentiment\")\n",
    ")\n",
    "\n",
    "# Test final version\n",
    "print(\"üéâ Production V2 - 100% Sonnet 4.0o-mini\\n\")\n",
    "\n",
    "samples = [\"Amazing!\", \"Terrible.\", \"Okay.\"]\n",
    "for text in samples:\n",
    "    result = prod_v2(text=text)\n",
    "    print(f\"'{text}' ‚Üí {result.content}\")\n",
    "\n",
    "print(\"\\n‚úÖ Migration complete!\")\n",
    "print(\"\\nüìà Achieved:\")\n",
    "print(\"   ‚Ä¢ 2.5x faster\")\n",
    "print(\"   ‚Ä¢ 50x cheaper\")\n",
    "print(\"   ‚Ä¢ Same quality\")\n",
    "print(\"   ‚Ä¢ Zero downtime\")\n",
    "print(\"   ‚Ä¢ All tracked in MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Summary\n",
    "\n",
    "## Part 1: Fundamentals ‚úÖ\n",
    "\n",
    "### 1. Automatic Tracing\n",
    "- `Agent(model='...')` - creates agent\n",
    "- `agent(query)` - automatic MLflow run!\n",
    "- `response.cost`, `response.latency` - automatic metrics\n",
    "- `response.print_links()` - MLflow UI links\n",
    "\n",
    "### 2. Prompt Versioning\n",
    "- `prompt_name=\"...\"` - triggers versioning\n",
    "- `agent.prompt_registry.add_version()` - add version\n",
    "- `agent.prompt_registry.get_latest()` - retrieve\n",
    "- `agent.prompt_registry.list_versions()` - history\n",
    "\n",
    "## Part 2: Model Migration ‚úÖ\n",
    "\n",
    "Migrated **Claude Sonnet 4.0 ‚Üí Claude Sonnet 4.0o-mini** with:\n",
    "\n",
    "1. **Baseline** - 10 runs created automatically\n",
    "2. **New Model Test** - 10 runs created automatically\n",
    "3. **Optimization** - Used DSPy suggestions\n",
    "4. **Evaluation** - 10 runs created automatically\n",
    "5. **A/B Testing** - Traffic split tracked automatically\n",
    "6. **Full Migration** - 100% rollout\n",
    "\n",
    "**Total: ~30+ MLflow runs with ZERO manual logging!**\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Takeaway\n",
    "\n",
    "### Inline API = Zero Boilerplate\n",
    "\n",
    "```python\n",
    "# Just call - everything automatic!\n",
    "agent = Agent(model='...')\n",
    "response = agent(query)  # MLflow run created!\n",
    "print(response.cost)     # Automatic metrics!\n",
    "```\n",
    "\n",
    "**More insights, less code, always at the frontier!** üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [MLflow Auto-rewrite Prompts](https://mlflow.org/docs/latest/genai/prompt-registry/rewrite-prompts/)\n",
    "- [MLflow Evaluation](https://mlflow.org/docs/latest/genai/eval-monitor/quickstart/)\n",
    "- [Prompt Management](https://mlflow.org/docs/latest/genai/prompt-registry/create-edit-prompts/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
