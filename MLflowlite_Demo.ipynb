{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow AI Gateway: Stay at the Frontier\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "When new models (GPT-5, Claude Sonnet 4.5, Gemini 2.5) are released, platform teams need to **evaluate, compare, and gradually migrate** \u2014 balancing **quality, latency, cost, and governance** \u2014 without breaking production.\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "**Part 1: Fundamentals** (5 min)\n",
    "1. \u2705 Automated tracing - every call logged\n",
    "2. \ud83d\udcdd Prompt versioning - register and compare\n",
    "\n",
    "**Part 2: Model Migration Workflow** (15 min)\n",
    "3. \ud83d\udd04 Baseline from current model\n",
    "4. \ud83c\udfaf Auto-optimize for new model\n",
    "5. \ud83d\udcca Compare quality, latency, cost\n",
    "6. \ud83d\ude80 Gradual A/B migration\n",
    "\n",
    "**Key:** Inline APIs - just call, automatic MLflow tracking!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import osimport warningsimport loggingwarnings.filterwarnings('ignore')logging.getLogger('LiteLLM').setLevel(logging.ERROR)  # Suppress LiteLLM info messages# \u26a0\ufe0f Set your API key here (or use .env file)# Option 1: Set directly (for quick demo)if 'ANTHROPIC_API_KEY' not in os.environ:    os.environ['ANTHROPIC_API_KEY'] = 'your-anthropic-api-key-here'  # \ud83d\udc48 Replace with your key# Option 2: Load from .env file (recommended)# from dotenv import load_dotenv# load_dotenv()# \ud83d\udca1 For Databricks: Set Unity Catalog schema for prompts (optional)# os.environ['MLFLOW_PROMPT_REGISTRY_UC_SCHEMA'] = 'your_catalog.your_schema'# Force reload module (fixes Cursor/VS Code notebook caching)import sysif 'mlflowlite' in sys.modules:    del sys.modules['mlflowlite']# Import everything you needfrom mlflowlite import (    Agent,    print_suggestions,    query,    set_timeout,    set_max_retries,    set_fallback_models,    smart_query,    create_ab_test)print(\"\u2705 Setup complete!\")if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'your-api-key-here':    print(\"\ud83d\udd11 API key configured\")else:    print(\"\u26a0\ufe0f  Please set your ANTHROPIC_API_KEY in the cell above\")print(\"\\n\ud83d\udca1 ONE unified interface: Agent\")print(\"   \u2022 Simple queries: agent(prompt)\")print(\"   \u2022 Advanced workflows: agent.run(query)\")print(\"\\n\ud83d\udce6 Ready to demonstrate:\")print(\"   1\ufe0f\u20e3  Automatic MLflow Tracing\")print(\"   2\ufe0f\u20e3  Prompt Management & Versioning\")print(\"   3\ufe0f\u20e3  DSPy-Style Optimization\")print(\"   4\ufe0f\u20e3  Reliability Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Fundamentals\n",
    "\n",
    "## \ud83d\udcca Feature 1: Automatic Tracing\n",
    "\n",
    "### The Old Way (Without Tracing)\n",
    "\n",
    "```python\n",
    "response = openai.chat.completions.create(...)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "Questions you can't answer:\n",
    "- \u2753 How much did that cost?\n",
    "- \u2753 How long did it take?\n",
    "- \u2753 Can I compare versions?\n",
    "\n",
    "**You're flying blind!** \ud83d\udee9\ufe0f\ud83d\udca8\n",
    "\n",
    "---\n",
    "\n",
    "### The New Way (With mlflowlite)\n",
    "\n",
    "Same code, **automatic insights**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent - automatically traced!",
    "agent = Agent(model='claude-sonnet-4-20250514')",
    "response = agent(\"Classify sentiment as positive/negative/neutral: This product is amazing!\")",
    "",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \ud83c\udfaf Value Unlocked: See Everything Automatically\n",
    "print(f\"Cost: ${response.cost:.4f} | Tokens: {response.usage.get('total_tokens', 0)} | Latency: {response.latency:.2f}s\")\n",
    "\n",
    "# View in MLflow UI\n",
    "response.print_links()\n",
    "\n",
    "print(\"\\n\u2705 Automatic tracking:\")\n",
    "print(\"   \u2022 Cost\")\n",
    "print(\"   \u2022 Latency\")\n",
    "print(\"   \u2022 Tokens\")\n",
    "print(\"   \u2022 MLflow run created\")\n",
    "print(\"   \u2022 UI links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## \ud83d\udcdd Feature 2: Prompt Versioning\n",
    "\n",
    "### The Old Way (Without Versioning)\n",
    "\n",
    "**Monday:** Great prompt!\n",
    "\n",
    "**Tuesday:** \"Improved\" it. Now slower and costly.\n",
    "\n",
    "**Wednesday:** Want Monday's version... \ud83d\ude31 **Didn't save it!**\n",
    "\n",
    "**You're guessing in the dark!** \ud83c\udfb2\n",
    "\n",
    "---\n",
    "\n",
    "### The New Way (With Prompt Versioning)\n",
    "\n",
    "Track every version. Compare with real numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create agent with prompt versioning",
    "agent = Agent(",
    "    model=\"claude-sonnet-4-20250514\",",
    "    prompt=\"Classify sentiment: {{text}}\",",
    "    prompt_name=\"sentiment_classifier\"  # \ud83d\udc48 Triggers versioning!",
    ")",
    "",
    "print(\"\u2705 Agent created with prompt versioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test v1\n",
    "result_v1 = agent(text=\"The service was excellent!\")\n",
    "print(f\"v1: {result_v1.usage['total_tokens']} tokens, ${result_v1.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add improved version\n",
    "agent.prompt_registry.add_version(\n",
    "    system_prompt=\"\"\"Classify sentiment. Answer ONLY: positive, negative, or neutral.\n",
    "\n",
    "Text: {{text}}\"\"\",\n",
    "    user_template=\"{{query}}\",\n",
    "    metadata={\"change\": \"More explicit instructions\"}\n",
    ")\n",
    "\n",
    "print(f\"\u2705 v{agent.prompt_registry.get_latest().version} registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test v2\n",
    "result_v2 = agent(text=\"The service was excellent!\")\n",
    "print(f\"v2: {result_v2.usage['total_tokens']} tokens, ${result_v2.cost:.4f}\")\n",
    "\n",
    "# Compare\n",
    "tokens_saved = result_v1.usage['total_tokens'] - result_v2.usage['total_tokens']\n",
    "print(f\"\\n\ud83d\udcb0 Difference: {tokens_saved} tokens, ${result_v1.cost - result_v2.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### \ud83d\udcda Inline Prompt Retrieval\n",
    "\n",
    "Use any prompt version directly - switch versions on the fly!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get specific version and use it inline",
    "v1 = agent.prompt_registry.get_version(1)",
    "v2 = agent.prompt_registry.get_version(2)",
    "",
    "# Use v1 inline",
    "test_agent_v1 = Agent(model=\"claude-sonnet-4-20250514\", prompt=v1.system_prompt)",
    "result1 = test_agent_v1(text=\"The service was excellent!\")",
    "print(f\"v1: {result1.content}\")",
    "",
    "# Use v2 inline",
    "test_agent_v2 = Agent(model=\"claude-sonnet-4-20250514\", prompt=v2.system_prompt)",
    "result2 = test_agent_v2(text=\"The service was excellent!\")",
    "print(f\"v2: {result2.content}\")",
    "",
    "print(\"\\n\u2705 Inline retrieval:\")",
    "print(\"   \u2022 Get version: agent.prompt_registry.get_version(n)\")",
    "print(\"   \u2022 Use immediately: Agent(prompt=v.system_prompt)\")",
    "print(\"   \u2022 Switch versions on the fly\")",
    "print(\"   \u2022 No need to recreate original agent\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View history\n",
    "history = agent.prompt_registry.list_versions()\n",
    "print(\"\\n\ud83d\udcda Version History:\")\n",
    "for item in history[-2:]:\n",
    "    print(f\"  v{item['version']}: {item['metadata'].get('change', 'Initial')}\")\n",
    "\n",
    "print(\"\\n\u2705 Git-like versioning for prompts!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Model Migration Workflow\n",
    "\n",
    "## \ud83c\udfaf The Scenario\n",
    "\n",
    "**Production:** Sentiment classifier using Claude Sonnet 4.0\n",
    "\n",
    "**New Release:** Claude Sonnet 4.0o-mini (faster, 50x cheaper!)\n",
    "\n",
    "**Question:** Can you migrate without breaking production?\n",
    "\n",
    "**Answer:** Yes! With inline APIs and automatic tracking.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Your Production App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production classifier (Sonnet 4.0)prod_agent = Agent(    model=\"claude-sonnet-4-20250514\",    prompt=\"Classify sentiment as positive, negative, or neutral: {{text}}\",    prompt_name=\"production_sentiment\")# Test current productionresult = prod_agent(text=\"Amazing product!\")print(f\"Sonnet 4.0 Result: {result.content}\")print(f\"Cost: ${result.cost:.4f} | Latency: {result.latency:.2f}s\")print(\"\\n\u2705 Current production: Sonnet 4.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collect Baseline Data\n",
    "\n",
    "Each call creates MLflow run automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production test cases\n",
    "test_cases = [\n",
    "    \"This movie was fantastic!\",\n",
    "    \"The service was terrible.\",\n",
    "    \"It was okay.\",\n",
    "    \"Very disappointed.\",\n",
    "    \"Best experience ever!\",\n",
    "    \"Works as described.\",\n",
    "    \"Can't believe how amazing!\",\n",
    "    \"Worst support ever.\",\n",
    "    \"Fine for the price.\",\n",
    "    \"Exceeded expectations!\"\n",
    "]\n",
    "\n",
    "# Collect baseline\n",
    "print(\"\ud83d\udd04 Collecting baseline from Sonnet 4.0...\\n\")\n",
    "baseline = []\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    result = prod_agent(text=text)  # Auto-creates MLflow run!\n",
    "    sentiment = result.content.lower().strip()\n",
    "    baseline.append(sentiment)\n",
    "    print(f\"{i}. {text[:30]:30s} \u2192 {sentiment}\")\n",
    "\n",
    "print(f\"\\n\u2705 {len(baseline)} baseline outputs\")\n",
    "print(f\"\u2705 {len(baseline)} MLflow runs created automatically!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Test New Model\n",
    "\n",
    "Test Claude Sonnet 4.0o-mini with same prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# New model agent\n",
    "new_agent = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=prod_agent.prompt_registry.get_latest().system_prompt  # Same prompt\n",
    ")\n",
    "\n",
    "# Test new model\n",
    "print(\"\ud83d\udd04 Testing Sonnet 4.0o-mini...\\n\")\n",
    "new_outputs = []\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    result = new_agent(text=text)  # Auto-creates MLflow run!\n",
    "    sentiment = result.content.lower().strip()\n",
    "    new_outputs.append(sentiment)\n",
    "    match = \"\u2705\" if sentiment == baseline[i-1] else \"\u274c\"\n",
    "    print(f\"{i}. {match} new: {sentiment:8s} (baseline: {baseline[i-1]})\")\n",
    "\n",
    "# Calculate consistency\n",
    "matches = sum(1 for n, b in zip(new_outputs, baseline) if n == b)\n",
    "consistency = matches / len(baseline) * 100\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Consistency: {consistency:.0f}%\")\n",
    "print(f\"\u2705 {len(new_outputs)} more MLflow runs created!\")\n",
    "if consistency < 90:\n",
    "    print(\"\\n\u26a0\ufe0f Need optimization!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Auto-Optimize Prompt\n",
    "\n",
    "Use DSPy suggestions to optimize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get optimization suggestions\n",
    "sample = prod_agent(text=\"This product is good\")\n",
    "print(\"\ud83c\udfaf Getting optimization suggestions...\\n\")\n",
    "print_suggestions(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create optimized version based on suggestions\n",
    "prod_agent.prompt_registry.add_version(\n",
    "    system_prompt=\"\"\"Classify sentiment of the text.\n",
    "\n",
    "Rules:\n",
    "- Answer ONLY with: positive, negative, or neutral\n",
    "- Use lowercase\n",
    "- No explanation\n",
    "\n",
    "Text: {{text}}\n",
    "\n",
    "Answer:\"\"\",\n",
    "    user_template=\"{{query}}\",\n",
    "    metadata={\"change\": \"Optimized for Sonnet 4.0o-mini\"}\n",
    ")\n",
    "\n",
    "print(f\"\u2705 Optimized prompt v{prod_agent.prompt_registry.get_latest().version} registered\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Evaluate Optimized Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimized agent\n",
    "opt_agent = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=prod_agent.prompt_registry.get_latest().system_prompt  # Optimized prompt\n",
    ")\n",
    "\n",
    "# Test optimized\n",
    "print(\"\ud83d\udd04 Testing optimized version...\\n\")\n",
    "opt_outputs = []\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    result = opt_agent(text=text)  # Auto-creates MLflow run!\n",
    "    sentiment = result.content.lower().strip()\n",
    "    opt_outputs.append(sentiment)\n",
    "    match = \"\u2705\" if sentiment == baseline[i-1] else \"\u274c\"\n",
    "    print(f\"{i}. {match} opt: {sentiment:8s} (baseline: {baseline[i-1]})\")\n",
    "\n",
    "# Calculate improvement\n",
    "matches = sum(1 for o, b in zip(opt_outputs, baseline) if o == b)\n",
    "improved = matches / len(baseline) * 100\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Before: {consistency:.0f}% | After: {improved:.0f}%\")\n",
    "print(f\"\ud83c\udf89 Improvement: +{improved - consistency:.0f} points!\")\n",
    "print(f\"\\n\u2705 {len(opt_outputs)} more MLflow runs!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"Sonnet 4.0\",\n",
    "        \"Prompt\": \"Original\",\n",
    "        \"Consistency\": \"100%\",\n",
    "        \"Latency\": \"~800ms\",\n",
    "        \"Cost/1M\": \"$30\",\n",
    "        \"Status\": \"\ud83d\udfe2 Production\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Sonnet 4.0o-mini\",\n",
    "        \"Prompt\": \"Original\",\n",
    "        \"Consistency\": f\"{consistency:.0f}%\",\n",
    "        \"Latency\": \"~300ms\",\n",
    "        \"Cost/1M\": \"$0.60\",\n",
    "        \"Status\": \"\u274c Not Ready\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Sonnet 4.0o-mini\",\n",
    "        \"Prompt\": \"Optimized\",\n",
    "        \"Consistency\": f\"{improved:.0f}%\",\n",
    "        \"Latency\": \"~300ms\",\n",
    "        \"Cost/1M\": \"$0.60\",\n",
    "        \"Status\": \"\u2705 Ready!\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\n\ud83d\udcca Model Comparison:\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Benefits:\")\n",
    "print(\"   \u2022 2.5x faster\")\n",
    "print(\"   \u2022 50x cheaper\")\n",
    "print(\"   \u2022 Same quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Gradual Migration (A/B Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A/B test: 80% Sonnet 4.0, 20% Sonnet 4.0o-mini\n",
    "migration_test = create_ab_test(\n",
    "    name=\"sonnet4_to_45_migration\",\n",
    "    variants={\n",
    "        'sonnet4': {\n",
    "            'model': 'claude-sonnet-4-20250514',\n",
    "            'weight': 80,\n",
    "            'prompt': prod_agent.prompt_registry.list_versions()[0]['system_prompt']\n",
    "        },\n",
    "        'sonnet45': {\n",
    "            'model': 'claude-sonnet-4.5-20251022',\n",
    "            'weight': 20,\n",
    "            'prompt': prod_agent.prompt_registry.get_latest().system_prompt\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"\u2705 A/B test created: 80% Sonnet 4.0, 20% Sonnet 4.0o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate production traffic\n",
    "print(\"\ud83d\ude80 Simulating traffic...\\n\")\n",
    "\n",
    "stats = {'sonnet4': 0, 'sonnet45': 0}\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    variant, response = migration_test.run(\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Classify: {text}\"}]\n",
    "    )  # Auto-creates MLflow run!\n",
    "    stats[variant] += 1\n",
    "    print(f\"{i}. {variant:12s} | {response.content.lower()[:8]:8s} | ${response.cost:.4f}\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Distribution:\")\n",
    "for variant, count in stats.items():\n",
    "    print(f\"   {variant}: {count}/{len(test_cases)} ({count*10}%)\")\n",
    "\n",
    "print(f\"\\n\u2705 {len(test_cases)} MLflow runs created automatically!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View A/B test results\n",
    "migration_test.print_report()\n",
    "\n",
    "print(\"\\n\ud83d\udca1 Migration path:\")\n",
    "print(\"   5% \u2192 20% \u2192 50% \u2192 80% \u2192 100%\")\n",
    "print(\"   Monitor MLflow UI at each step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Full Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production V2: 100% Sonnet 4.0o-mini\n",
    "prod_v2 = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=prod_agent.prompt_registry.get_latest().system_prompt\n",
    ")\n",
    "\n",
    "# Test final version\n",
    "print(\"\ud83c\udf89 Production V2 - 100% Sonnet 4.0o-mini\\n\")\n",
    "\n",
    "samples = [\"Amazing!\", \"Terrible.\", \"Okay.\"]\n",
    "for text in samples:\n",
    "    result = prod_v2(text=text)\n",
    "    print(f\"'{text}' \u2192 {result.content}\")\n",
    "\n",
    "print(\"\\n\u2705 Migration complete!\")\n",
    "print(\"\\n\ud83d\udcc8 Achieved:\")\n",
    "print(\"   \u2022 2.5x faster\")\n",
    "print(\"   \u2022 50x cheaper\")\n",
    "print(\"   \u2022 Same quality\")\n",
    "print(\"   \u2022 Zero downtime\")\n",
    "print(\"   \u2022 All tracked in MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# \ud83c\udfaf Summary\n",
    "\n",
    "## Part 1: Fundamentals \u2705\n",
    "\n",
    "### 1. Automatic Tracing\n",
    "- `Agent(model='...')` - creates agent\n",
    "- `agent(query)` - automatic MLflow run!\n",
    "- `response.cost`, `response.latency` - automatic metrics\n",
    "- `response.print_links()` - MLflow UI links\n",
    "\n",
    "### 2. Prompt Versioning\n",
    "- `prompt_name=\"...\"` - triggers versioning\n",
    "- `agent.prompt_registry.add_version()` - add version\n",
    "- `agent.prompt_registry.get_latest()` - retrieve\n",
    "- `agent.prompt_registry.list_versions()` - history\n",
    "\n",
    "## Part 2: Model Migration \u2705\n",
    "\n",
    "Migrated **Claude Sonnet 4.0 \u2192 Claude Sonnet 4.0o-mini** with:\n",
    "\n",
    "1. **Baseline** - 10 runs created automatically\n",
    "2. **New Model Test** - 10 runs created automatically\n",
    "3. **Optimization** - Used DSPy suggestions\n",
    "4. **Evaluation** - 10 runs created automatically\n",
    "5. **A/B Testing** - Traffic split tracked automatically\n",
    "6. **Full Migration** - 100% rollout\n",
    "\n",
    "**Total: ~30+ MLflow runs with ZERO manual logging!**\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udd11 Key Takeaway\n",
    "\n",
    "### Inline API = Zero Boilerplate\n",
    "\n",
    "```python\n",
    "# Just call - everything automatic!\n",
    "agent = Agent(model='...')\n",
    "response = agent(query)  # MLflow run created!\n",
    "print(response.cost)     # Automatic metrics!\n",
    "```\n",
    "\n",
    "**More insights, less code, always at the frontier!** \ud83d\ude80\n",
    "\n",
    "---\n",
    "\n",
    "## \ud83d\udcda Resources\n",
    "\n",
    "- [MLflow Auto-rewrite Prompts](https://mlflow.org/docs/latest/genai/prompt-registry/rewrite-prompts/)\n",
    "- [MLflow Evaluation](https://mlflow.org/docs/latest/genai/eval-monitor/quickstart/)\n",
    "- [Prompt Management](https://mlflow.org/docs/latest/genai/prompt-registry/create-edit-prompts/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}