{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlflowlite Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Table of Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "2. [The Scenario](#the-scenario)\n",
    "3. [Feature 1: Automatic Tracing](#feature-1-automatic-tracing)\n",
    "4. [Feature 2: Prompt Management & Versioning](#feature-2-prompt-management--versioning)\n",
    "5. [Feature 3: DSPy-Style Optimization](#feature-3-dspy-style-optimization)\n",
    "6. [Feature 4: Reliability Features](#feature-4-reliability-features)\n",
    "7. [What You Just Learned](#what-you-just-learned)\n",
    "8. [Advanced: Smart Routing & A/B Testing](#advanced-smart-routing--ab-testing)\n",
    "9. [Next Steps](#next-steps)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install if needed (uncomment if running for first time)\n",
    "# !pip install -e ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Setup complete!\n",
      "üîë API key configured\n",
      "\n",
      "üí° ONE unified interface: Agent\n",
      "   ‚Ä¢ Simple queries: agent(prompt)\n",
      "   ‚Ä¢ Advanced workflows: agent.run(query)\n",
      "\n",
      "üì¶ Ready to demonstrate:\n",
      "   1Ô∏è‚É£  Automatic MLflow Tracing\n",
      "   2Ô∏è‚É£  Prompt Management & Versioning\n",
      "   3Ô∏è‚É£  DSPy-Style Optimization\n",
      "   4Ô∏è‚É£  Reliability Features\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('LiteLLM').setLevel(logging.ERROR)  # Suppress LiteLLM info messages\n",
    "\n",
    "# ‚ö†Ô∏è Set your API key here (or use .env file)\n",
    "# Option 1: Set directly (for quick demo)\n",
    "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
    "    os.environ['ANTHROPIC_API_KEY'] = 'your-api-key-here'  # üëà Replace with your key\n",
    "\n",
    "# Option 2: Load from .env file (recommended)\n",
    "# from dotenv import load_dotenv\n",
    "# load_dotenv()\n",
    "\n",
    "# Force reload module (fixes Cursor/VS Code notebook caching)\n",
    "import sys\n",
    "if 'mlflowlite' in sys.modules:\n",
    "    del sys.modules['mlflowlite']\n",
    "\n",
    "# Import everything you need\n",
    "from mlflowlite import (\n",
    "    Agent,\n",
    "    print_suggestions,\n",
    "    query,\n",
    "    set_timeout,\n",
    "    set_max_retries,\n",
    "    set_fallback_models,\n",
    "    smart_query,\n",
    "    create_ab_test\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'your-api-key-here':\n",
    "    print(\"üîë API key configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please set your ANTHROPIC_API_KEY in the cell above\")\n",
    "print(\"\\nüí° ONE unified interface: Agent\")\n",
    "print(\"   ‚Ä¢ Simple queries: agent(prompt)\")\n",
    "print(\"   ‚Ä¢ Advanced workflows: agent.run(query)\")\n",
    "print(\"\\nüì¶ Ready to demonstrate:\")\n",
    "print(\"   1Ô∏è‚É£  Automatic MLflow Tracing\")\n",
    "print(\"   2Ô∏è‚É£  Prompt Management & Versioning\")\n",
    "print(\"   3Ô∏è‚É£  DSPy-Style Optimization\")\n",
    "print(\"   4Ô∏è‚É£  Reliability Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìß The Scenario: A Support Ticket\n",
    "\n",
    "Imagine you're building a support bot. You get this ticket:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìã Sample Support Ticket:\n",
      "\n",
      "Subject: Unable to access dashboard\n",
      "\n",
      "User reported that they cannot access the analytics dashboard.\n",
      "They receive a 403 Forbidden error when clicking on the dashboard link.\n",
      "User role: Manager\n",
      "Last successful access: 2 days ago\n",
      "Browser: Chrome 120\n",
      "\n"
     ]
    }
   ],
   "source": [
    "support_ticket = \"\"\"\n",
    "Subject: Unable to access dashboard\n",
    "\n",
    "User reported that they cannot access the analytics dashboard.\n",
    "They receive a 403 Forbidden error when clicking on the dashboard link.\n",
    "User role: Manager\n",
    "Last successful access: 2 days ago\n",
    "Browser: Chrome 120\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìã Sample Support Ticket:\")\n",
    "print(support_ticket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä Feature 1: Automatic Tracing\n",
    "\n",
    "## The Old Way (Without Tracing)\n",
    "\n",
    "You call an LLM:\n",
    "```python\n",
    "response = openai.chat.completions.create(...)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Questions you can't answer:**\n",
    "- ‚ùì How much did that cost?\n",
    "- ‚ùì How long did it take?\n",
    "- ‚ùì Was the response quality good?\n",
    "- ‚ùì Can I compare this to yesterday's version?\n",
    "\n",
    "**You're flying blind! üõ©Ô∏èüí®**\n",
    "\n",
    "---\n",
    "\n",
    "## The New Way (With mlflowlite)\n",
    "\n",
    "**Same code, automatic insights:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A manager reported being unable to access the analytics dashboard, receiving a 403 Forbidden error when clicking the link. The issue started 2 days ago, and the user is accessing the dashboard using Chrome version 120.\n"
     ]
    }
   ],
   "source": [
    "# Create an agent and make a query - automatically traced!\n",
    "agent = Agent(model='claude-3-5-sonnet-20240620')\n",
    "response1 = agent(f\"Summarize this support ticket in 2 sentences:\\n\\n{support_ticket}\")\n",
    "\n",
    "print(response1.content)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Value Unlocked: See Everything Automatically\n",
    "\n",
    "**Look what you get for FREE:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: $0.0010 | Tokens: 124 | Latency: 3.18s\n",
      "\n",
      "üîó MLflow UI Links:\n",
      "   üìä Run Details: http://localhost:5000/#/experiments/809917521309205504/runs/668244eb7da54424900244ef98b06fd2\n",
      "   üß™ Experiment: http://localhost:5000/#/experiments/809917521309205504\n",
      "   üìÅ Artifacts: http://localhost:5000/#/experiments/809917521309205504/runs/668244eb7da54424900244ef98b06fd2/artifactPath\n",
      "\n",
      "   üí° Tip: Click Cmd/Ctrl + Click to open in browser\n"
     ]
    }
   ],
   "source": [
    "# Automatic metrics - no configuration needed!\n",
    "print(f\"Cost: ${response1.cost:.4f} | Tokens: {response1.usage.get('total_tokens', 0)} | Latency: {response1.latency:.2f}s\")\n",
    "\n",
    "# View in MLflow UI\n",
    "response1.print_links()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìù Feature 2: Prompt Versioning\n",
    "\n",
    "## The Old Way (Without Versioning)\n",
    "\n",
    "**Monday:** You write a prompt. It works great!\n",
    "\n",
    "**Tuesday:** You \"improve\" it. Now it's slower and costs more.\n",
    "\n",
    "**Wednesday:** You want the Monday version back but... üò± **You didn't save it!**\n",
    "\n",
    "**Questions you can't answer:**\n",
    "- ‚ùì Which version was cheaper?\n",
    "- ‚ùì Which version was faster?\n",
    "- ‚ùì What exactly did I change?\n",
    "- ‚ùì Can I roll back?\n",
    "\n",
    "**You're guessing in the dark! üé≤**\n",
    "\n",
    "---\n",
    "\n",
    "## The New Way (With Prompt Versioning)\n",
    "\n",
    "**Track every version automatically. Compare with real numbers.**\n",
    "\n",
    "Let's see a dramatic example of prompt optimization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'agent_support_bot_prompt' version 9 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí agent_support_bot_prompt\n",
      "Created agent with prompt v9\n"
     ]
    }
   ],
   "source": [
    "# Create versioned agent (prompts tracked automatically)\n",
    "agent = Agent(\n",
    "    name=\"support_bot\",\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    system_prompt=\"\"\"You are a helpful support bot. Analyze support tickets and provide:\n",
    "1. Quick summary\n",
    "2. Root cause analysis\n",
    "3. Recommended actions\n",
    "\n",
    "Be concise and actionable.\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Created agent with prompt v{agent.prompt_registry.get_latest().version}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Version 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 278 tokens, $0.0028\n"
     ]
    }
   ],
   "source": [
    "# Test version 1\n",
    "result_v1 = agent.run(f\"Analyze this ticket:\\n\\n{support_ticket}\")\n",
    "print(f\"v1: {result_v1.trace.total_tokens} tokens, ${result_v1.trace.total_cost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Hypothesis: A Tighter Prompt Will Save Tokens\n",
    "\n",
    "**The insight:** Maybe we don't need all that detail for every ticket.\n",
    "\n",
    "Let's try a more concise version and **measure the difference**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'agent_support_bot_prompt' version 10 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí agent_support_bot_prompt\n",
      "v10 created\n"
     ]
    }
   ],
   "source": [
    "# Create improved version 2\n",
    "agent.prompt_registry.add_version(\n",
    "    system_prompt=\"\"\"You are a support bot. For each ticket provide:\n",
    "1. Issue summary (1 line)\n",
    "2. Root cause (1 line)  \n",
    "3. Fix (1-2 lines)\n",
    "\n",
    "Be extremely concise.\"\"\",\n",
    "    user_template=\"{query}\",\n",
    "    metadata={\"change\": \"Made more concise\"}\n",
    ")\n",
    "print(f\"v{agent.prompt_registry.get_latest().version} created\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2: 155 tokens, $0.0015\n"
     ]
    }
   ],
   "source": [
    "# Test version 2\n",
    "result_v2 = agent.run(f\"Analyze this ticket:\\n\\n{support_ticket}\")\n",
    "print(f\"v2: {result_v2.trace.total_tokens} tokens, ${result_v2.trace.total_cost:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ The Moment of Truth: Side-by-Side Comparison\n",
    "\n",
    "**Did the concise prompt actually save money?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved: 123 tokens (44%), $0.0012/query\n",
      "At scale: $36.90/month on 1K queries/day\n"
     ]
    }
   ],
   "source": [
    "# Compare versions\n",
    "tokens_saved = result_v1.trace.total_tokens - result_v2.trace.total_tokens\n",
    "cost_saved = result_v1.trace.total_cost - result_v2.trace.total_cost\n",
    "savings_pct = (tokens_saved / result_v1.trace.total_tokens) * 100\n",
    "\n",
    "print(f\"Saved: {tokens_saved} tokens ({savings_pct:.0f}%), ${cost_saved:.4f}/query\")\n",
    "print(f\"At scale: ${cost_saved * 1000 * 30:.2f}/month on 1K queries/day\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v8: Made more concise\n",
      "v9: Initial\n",
      "v10: Made more concise\n"
     ]
    }
   ],
   "source": [
    "# View prompt history\n",
    "history = agent.prompt_registry.list_versions()\n",
    "for item in history[-3:]:\n",
    "    print(f\"v{item['version']}: {item['metadata'].get('change', 'Initial')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üß† Feature 3: DSPy-Style Optimization\n",
    "\n",
    "## The Problem: Prompt Engineering is Guesswork\n",
    "\n",
    "**You:** \"Hmm, this prompt could be better...\"\n",
    "\n",
    "**Also you:** \"But... how? What should I change?\"\n",
    "\n",
    "**Your options without DSPy:**\n",
    "1. ‚ùì Guess and try random changes\n",
    "2. ‚ùì Ask a colleague (who also guesses)\n",
    "3. ‚ùì Read generic advice like \"be more specific\"\n",
    "4. ‚ùì No way to know if changes actually helped\n",
    "\n",
    "**Result: You're optimizing blind!** üéØ\n",
    "\n",
    "---\n",
    "\n",
    "## The Solution: DSPy Finds the Best Prompt Automatically\n",
    "\n",
    "**Watch DSPy work its magic:**\n",
    "\n",
    "1. üîç **Analyze** your current prompt\n",
    "2. üß† **Generate** an optimized version\n",
    "3. üìù **Register** it in Prompt Registry\n",
    "4. üß™ **Test** both versions\n",
    "5. üìä **Prove** the optimized version is better with metrics\n",
    "\n",
    "**Then the Prompt Registry shows it's the BEST prompt!**\n",
    "\n",
    "Let's see it in action:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "üí° Improvement Suggestions (LLM)\n",
      "============================================================\n",
      "\n",
      "üìä Current Performance:\n",
      "  latency_ms: 3183.507\n",
      "  tokens: 124\n",
      "  cost_usd: 0.001\n",
      "  helpfulness: 0.900\n",
      "  conciseness: 0.900\n",
      "  speed: 0.700\n",
      "\n",
      "üîß Suggestions:\n",
      "  1. To increase helpfulness, the response should include specific troubleshooting steps for the 403 Forbidden error, such as checking user permissions, clearing browser cache/cookies, and contacting IT support if the issue persists.\n",
      "  2. For better accuracy, ask the model to verify that the provided Chrome version is supported for the analytics dashboard. If not, recommend updating to a compatible version.\n",
      "  3. To improve speed and reduce cost, try shortening the prompt by focusing on essential details like the error message, when it started, and the browser used. Remove less critical info.\n",
      "  4. Experiment with using a smaller, faster model for the initial response, and only use the larger model if more detailed troubleshooting is needed after gathering more context.\n",
      "  5. Restructure the prompt to put the most important information first, like: \"A manager is getting a 403 Forbidden error when trying to access the analytics dashboard for the past 2 days. Using Chrome version 120. What troubleshooting steps do you recommend?\"\n",
      "  6. Add a prompt instruction telling the model to provide a concise initial response with clear troubleshooting steps and when to escalate to IT. This can guide the model to give more actionable suggestions.\n",
      "\n",
      "üìù Powered by LLM analysis\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# DSPy analyzes your prompt automatically\n",
    "print_suggestions(response1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'agent_dspy_support_bot_prompt' version 11 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí agent_dspy_support_bot_prompt\n",
      "Baseline: 116 tokens\n"
     ]
    }
   ],
   "source": [
    "# Create agent and test baseline\n",
    "dspy_agent = Agent(\n",
    "    name=\"dspy_support_bot\",\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    system_prompt=\"You are a support bot. Analyze support tickets.\"\n",
    ")\n",
    "baseline_result = dspy_agent.run(f\"Summarize this support ticket in 2 sentences:\\n\\n{support_ticket}\")\n",
    "print(f\"Baseline: {baseline_result.trace.total_tokens} tokens\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'agent_dspy_support_bot_prompt' version 12 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí agent_dspy_support_bot_prompt\n",
      "DSPy-optimized prompt registered\n"
     ]
    }
   ],
   "source": [
    "# Apply DSPy-optimized prompt (structured output)\n",
    "dspy_agent.prompt_registry.add_version(\n",
    "    system_prompt=\"\"\"Support analyst. Provide:\n",
    "ISSUE: [one sentence]\n",
    "CAUSE: [likely root cause]\n",
    "FIX: [primary solution]\n",
    "\n",
    "Keep each section under 20 words.\"\"\",\n",
    "    user_template=\"{query}\",\n",
    "    metadata={\"change\": \"DSPy-optimized\", \"benefit\": \"Structured output\"}\n",
    ")\n",
    "print(\"DSPy-optimized prompt registered\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized: 140 tokens\n",
      "ISSUE: User unable to access analytics dashboard, receiving 403 Forbidden error.\n",
      "\n",
      "CAUSE: Permissions issue, likely due to recent role or access control changes.\n",
      "\n",
      "FIX: Verify user's role permissions and re-provision appropriate dashboard access in system.\n"
     ]
    }
   ],
   "source": [
    "# Test optimized prompt\n",
    "optimized_result = dspy_agent.run(f\"Analyze this support ticket:\\n\\n{support_ticket}\")\n",
    "print(f\"Optimized: {optimized_result.trace.total_tokens} tokens\")\n",
    "print(optimized_result.response)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result: Structured output (ISSUE/CAUSE/FIX)\n",
      "Benefit: Consistent, parseable, production-ready\n"
     ]
    }
   ],
   "source": [
    "# Compare results\n",
    "print(f\"Result: Structured output (ISSUE/CAUSE/FIX)\")\n",
    "print(f\"Benefit: Consistent, parseable, production-ready\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v11: Initial\n",
      "v12: DSPy-optimized üèÜ\n"
     ]
    }
   ],
   "source": [
    "# View optimized prompts in registry\n",
    "history = dspy_agent.prompt_registry.list_versions()\n",
    "for item in history[-2:]:\n",
    "    marker = \" üèÜ\" if item['metadata'].get('change') == 'DSPy-optimized' else \"\"\n",
    "    print(f\"v{item['version']}: {item['metadata'].get('change', 'Initial')}{marker}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîÑ Feature 4: Reliability Features\n",
    "\n",
    "**The Problem:** LLM APIs timeout, fail, or get rate-limited ‚Üí Your app breaks\n",
    "\n",
    "**The Solution:** Built-in retry, timeout, and fallback support ‚Üí Always available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reliability configured: 30s timeout, 5 retries, 4 fallback models\n"
     ]
    }
   ],
   "source": [
    "# Configure reliability: retry, timeout, fallbacks\n",
    "set_timeout(30)\n",
    "set_max_retries(5)\n",
    "set_fallback_models([\n",
    "    \"claude-3-5-haiku-20241022\",\n",
    "    \"claude-3-haiku-20240307\",\n",
    "    \"claude-3-7-sonnet-20250219\",\n",
    "    \"claude-instant-1.2\"\n",
    "])\n",
    "print(\"Reliability configured: 30s timeout, 5 retries, 4 fallback models\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-5-sonnet-20240620 | 2.09s | The circuit breaker pattern is a design pattern that prevents cascading failures...\n"
     ]
    }
   ],
   "source": [
    "# Per-request config\n",
    "response = query(\n",
    "    model=\"claude-3-5-sonnet-20240620\",\n",
    "    prompt=\"Explain circuit breaker pattern in one sentence\",\n",
    "    timeout=20,\n",
    "    max_retries=3,\n",
    "    fallback_models=[\"claude-3-5-haiku-20241022\", \"claude-3-opus-20240229\"]\n",
    ")\n",
    "print(f\"{response.model} | {response.latency:.2f}s | {response.content[:80]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Value\n",
    "\n",
    "**High Availability with 4+ Anthropic Models:**\n",
    "- Automatic failover across 4 backup models\n",
    "- Retry logic handles transient failures  \n",
    "- Timeout prevents hanging requests\n",
    "- Smart fallback: fast ‚Üí quality ‚Üí cheapest\n",
    "\n",
    "**Production Ready:**\n",
    "```python\n",
    "# 4-model fallback chain for maximum reliability\n",
    "set_fallback_models([\n",
    "    \"claude-3-5-haiku-20241022\",     # Fast & modern\n",
    "    \"claude-3-haiku-20240307\",        # Faster & cheaper\n",
    "    \"claude-3-7-sonnet-20250219\",     # Quality backup\n",
    "    \"claude-instant-1.2\"              # Cheapest option\n",
    "])\n",
    "```\n",
    "\n",
    "**Result:** 99.9% uptime with 4 backup models across Anthropic's full lineup!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üöÄ Advanced: Smart Routing & A/B Testing\n",
    "\n",
    "**For production applications:** Optimize costs and make data-driven decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Routing üß†\n",
    "\n",
    "Automatically select the best model based on query complexity.\n",
    "\n",
    "**The Problem:** Simple queries waste money on expensive models.\n",
    "\n",
    "**The Solution:** Smart routing analyzes complexity and picks the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-5-sonnet-20240620 | complexity=0.35 | cost=$0.0002\n"
     ]
    }
   ],
   "source": [
    "# Simple query ‚Üí automatically selects fast model\n",
    "decision, response = smart_query(\"What is 2+2?\")\n",
    "print(f\"{decision.model} | complexity={decision.complexity_score:.2f} | cost=${response.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "claude-3-5-sonnet-20240620 | complexity=0.40 | cost=$0.0113\n"
     ]
    }
   ],
   "source": [
    "# Complex query ‚Üí automatically selects quality model\n",
    "decision, response = smart_query(\"Analyze trade-offs between microservices and monoliths\")\n",
    "print(f\"{decision.model} | complexity={decision.complexity_score:.2f} | cost=${response.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Value\n",
    "\n",
    "**Cost Savings with 4+ Anthropic Models:**\n",
    "- Simple queries: Claude 3.5 Haiku ($0.001) vs Claude 3.5 Sonnet ($0.003) = **67% savings**\n",
    "- Medium queries: Claude 3.5 Sonnet (balanced)\n",
    "- Complex queries: Claude 3 Opus or Claude 3.7 Sonnet (quality)\n",
    "- Automatic routing across 4+ models\n",
    "- No manual routing logic needed\n",
    "\n",
    "**Anthropic Model Lineup:**\n",
    "1. **Claude 3.5 Haiku** - Fast & cheap ($0.001/1K tokens)\n",
    "2. **Claude 3 Haiku** - Faster & cheaper\n",
    "3. **Claude 3.5 Sonnet** - Balanced ($0.003/1K tokens)\n",
    "4. **Claude 3 Opus** - Quality ($0.015/1K tokens)\n",
    "5. **Claude 3.7 Sonnet** - Latest quality\n",
    "\n",
    "**Result:** $100 ‚Üí $55 monthly cost (45% average savings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A/B Testing üß™\n",
    "\n",
    "Compare models or prompts with automatic tracking.\n",
    "\n",
    "**The Problem:** Which model/prompt is actually better?\n",
    "\n",
    "**The Solution:** Data-driven A/B testing with automatic winner detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A/B test created: ['haiku', 'sonnet', 'opus']\n"
     ]
    }
   ],
   "source": [
    "# Create A/B test: compare 3 models\n",
    "test = create_ab_test(\n",
    "    name=\"anthropic_test\",\n",
    "    variants={\n",
    "        'haiku': {'model': 'claude-3-5-haiku-20241022'},\n",
    "        'sonnet': {'model': 'claude-3-5-sonnet-20240620'},\n",
    "        'opus': {'model': 'claude-3-opus-20240229'}\n",
    "    }\n",
    ")\n",
    "print(f\"A/B test created: {list(test.variants.keys())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sonnet | $0.0077 | 18.2s\n",
      "sonnet | $0.0049 | 11.0s\n",
      "sonnet | $0.0048 | 11.3s\n",
      "opus | $0.0297 | 12.9s\n",
      "sonnet | $0.0055 | 12.9s\n"
     ]
    }
   ],
   "source": [
    "# Run test\n",
    "queries = [\"Explain ML\", \"What are microservices?\", \"REST API?\", \"Cloud computing\", \"DevOps?\"]\n",
    "for query in queries:\n",
    "    variant, response = test.run(messages=[{\"role\": \"user\", \"content\": query}])\n",
    "    print(f\"{variant} | ${response.cost:.4f} | {response.latency:.1f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üìä A/B Test Report: anthropic_test\n",
      "======================================================================\n",
      "\n",
      "üîπ Variant: haiku\n",
      "   Config: {'model': 'claude-3-5-haiku-20241022'}\n",
      "   Status: No data yet\n",
      "\n",
      "üîπ Variant: sonnet\n",
      "   Config: {'model': 'claude-3-5-sonnet-20240620'}\n",
      "   Requests: 4\n",
      "   Avg Cost: $0.0057\n",
      "   Avg Latency: 13.34s\n",
      "   Avg Tokens: 392\n",
      "   Avg Scores: {'helpfulness': 0.9, 'conciseness': 0.6, 'speed': 0.6}\n",
      "\n",
      "üîπ Variant: opus\n",
      "   Config: {'model': 'claude-3-opus-20240229'}\n",
      "   Requests: 1\n",
      "   Avg Cost: $0.0297\n",
      "   Avg Latency: 12.86s\n",
      "   Avg Tokens: 403\n",
      "   Avg Scores: {'helpfulness': 0.9, 'conciseness': 0.6, 'speed': 0.6}\n",
      "\n",
      "======================================================================\n",
      "üèÜ Winners:\n",
      "   ‚Ä¢ Best cost: sonnet (0.005740499999999999)\n",
      "   ‚Ä¢ Best latency: opus (12.858946084976196)\n",
      "   ‚Ä¢ Best quality: sonnet (N/A)\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# View results\n",
    "test.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Winner: sonnet | $0.0057 avg | 4 requests\n"
     ]
    }
   ],
   "source": [
    "# Get winner\n",
    "winner, stats = test.get_winner('cost')\n",
    "print(f\"Winner: {winner} | ${stats['avg_cost']:.4f} avg | {stats['count']} requests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Value\n",
    "\n",
    "**Data-Driven Decisions:**\n",
    "- Test before committing to a model\n",
    "- Automatic tracking of all metrics\n",
    "- Clear winner detection\n",
    "- Compare anything: models, prompts, configs\n",
    "\n",
    "**Result:** Switch to winner ‚Üí save 20-40% on costs with same quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Advanced Features Summary\n",
    "\n",
    "**Smart Routing:**\n",
    "```python\n",
    "decision, response = mla.smart_query(\"Your query\")\n",
    "# Automatic model selection based on complexity\n",
    "```\n",
    "\n",
    "**A/B Testing:**\n",
    "```python\n",
    "test = mla.create_ab_test(name=\"test\", variants={...})\n",
    "variant, response = test.run(messages=[...])\n",
    "test.print_report()\n",
    "```\n",
    "\n",
    "**Combined Impact:**\n",
    "- 45% average cost reduction\n",
    "- Data-driven optimization\n",
    "- Production-ready reliability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
