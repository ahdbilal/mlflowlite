{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MLflow AI Gateway: Stay at the Frontier\n",
    "\n",
    "## The Challenge\n",
    "\n",
    "When new models (GPT-5, Claude Sonnet 4.5, Gemini 2.5) are released, platform teams need to **evaluate, compare, and gradually migrate** ‚Äî balancing **quality, latency, cost, and governance** ‚Äî without breaking production.\n",
    "\n",
    "---\n",
    "\n",
    "## What You'll Learn\n",
    "\n",
    "**Part 1: Fundamentals** (5 min)\n",
    "1. ‚úÖ Automated tracing - every call logged\n",
    "2. üìù Prompt versioning - register and compare\n",
    "\n",
    "**Part 2: Model Migration Workflow** (15 min)\n",
    "3. üîÑ Baseline from current model\n",
    "4. üéØ Auto-optimize for new model\n",
    "5. üìä Compare quality, latency, cost\n",
    "6. üöÄ Gradual A/B migration\n",
    "\n",
    "**Key:** Inline APIs - just call, automatic MLflow tracking!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Obtaining file:///Users/ahmed.bilal/Desktop/gateway-oss\n",
      "  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Checking if build backend supports build_editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build editable ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing editable metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting mlflow>=2.10.0 (from mlflowlite==0.1.0)\n",
      "  Using cached mlflow-3.6.0-py3-none-any.whl.metadata (31 kB)\n",
      "Collecting litellm>=1.30.0 (from mlflowlite==0.1.0)\n",
      "  Using cached litellm-1.79.1-py3-none-any.whl.metadata (30 kB)\n",
      "Collecting pydantic>=2.0.0 (from mlflowlite==0.1.0)\n",
      "  Using cached pydantic-2.12.4-py3-none-any.whl.metadata (89 kB)\n",
      "Collecting python-dotenv>=1.0.0 (from mlflowlite==0.1.0)\n",
      "  Using cached python_dotenv-1.2.1-py3-none-any.whl.metadata (25 kB)\n",
      "Collecting openai>=1.12.0 (from mlflowlite==0.1.0)\n",
      "  Using cached openai-2.7.1-py3-none-any.whl.metadata (29 kB)\n",
      "Collecting anthropic>=0.18.0 (from mlflowlite==0.1.0)\n",
      "  Using cached anthropic-0.72.0-py3-none-any.whl.metadata (28 kB)\n",
      "Collecting google-generativeai>=0.3.0 (from mlflowlite==0.1.0)\n",
      "  Using cached google_generativeai-0.8.5-py3-none-any.whl.metadata (3.9 kB)\n",
      "Collecting dspy-ai>=2.4.0 (from mlflowlite==0.1.0)\n",
      "  Using cached dspy_ai-3.0.3-py3-none-any.whl.metadata (285 bytes)\n"
     ]
    }
   ],
   "source": [
    "# Install mlflowlite (force reinstall to get latest fixes)\n",
    "%pip install -e . --force-reinstall"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîë API key configured\n",
      "‚úÖ Setup complete!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "import logging\n",
    "warnings.filterwarnings('ignore')\n",
    "logging.getLogger('LiteLLM').setLevel(logging.ERROR)  # Suppress LiteLLM info messages\n",
    "\n",
    "# ‚ö†Ô∏è Set your API key here \n",
    "if 'ANTHROPIC_API_KEY' not in os.environ:\n",
    "    os.environ['ANTHROPIC_API_KEY'] = 'your-anthropic-api-key-here'  # üëà Replace with your key\n",
    "\n",
    "# üí° For Databricks: Set Unity Catalog schema for prompts (optional)\n",
    "# os.environ['MLFLOW_PROMPT_REGISTRY_UC_SCHEMA'] = 'your_catalog.your_schema'\n",
    "\n",
    "# Force reload module (fixes Cursor/VS Code notebook caching)\n",
    "import sys\n",
    "if 'mlflowlite' in sys.modules:\n",
    "    del sys.modules['mlflowlite']\n",
    "\n",
    "# Import everything you need\n",
    "from mlflowlite import (\n",
    "    Agent,\n",
    "    load_prompt,\n",
    "    print_suggestions,\n",
    "    query,\n",
    "    set_timeout,\n",
    "    set_max_retries,\n",
    "    set_fallback_models,\n",
    "    smart_query,\n",
    "    create_ab_test\n",
    ")\n",
    "\n",
    "if os.environ.get('ANTHROPIC_API_KEY') and os.environ['ANTHROPIC_API_KEY'] != 'your-api-key-here':\n",
    "    print(\"üîë API key configured\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è  Please set your ANTHROPIC_API_KEY in the cell above\")\n",
    "print(\"‚úÖ Setup complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 1: Fundamentals\n",
    "\n",
    "## üìä Feature 1: Automatic Tracing\n",
    "\n",
    "### The Old Way (Without Tracing)\n",
    "\n",
    "```python\n",
    "response = openai.chat.completions.create(...)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "Questions you can't answer:\n",
    "- ‚ùì How much did that cost?\n",
    "- ‚ùì How long did it take?\n",
    "- ‚ùì Can I compare versions?\n",
    "\n",
    "**You're flying blind!** üõ©Ô∏èüí®\n",
    "\n",
    "---\n",
    "\n",
    "### The New Way (With mlflowlite)\n",
    "\n",
    "Same code, **automatic insights**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Positive**\n",
      "\n",
      "The sentiment is clearly positive due to the enthusiastic language (\"amazing!\") and exclamation mark, which indicates strong approval and satisfaction with the product.\n"
     ]
    }
   ],
   "source": [
    "# Create agent - automatically traced!\n",
    "agent = Agent(model='claude-sonnet-4-20250514')\n",
    "response = agent(\"Classify sentiment as positive/negative/neutral: This product is amazing!\")\n",
    "\n",
    "print(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cost: $0.0006 | Tokens: 61 | Latency: 3.34s\n",
      "\n",
      "üîó MLflow UI Links:\n",
      "   üìä Run Details: http://localhost:5000/#/experiments/809917521309205504/runs/5555e9d6bfc14e929336c0f9e1415b4a\n",
      "   üß™ Experiment: http://localhost:5000/#/experiments/809917521309205504\n",
      "   üìÅ Artifacts: http://localhost:5000/#/experiments/809917521309205504/runs/5555e9d6bfc14e929336c0f9e1415b4a/artifactPath\n",
      "\n",
      "   üí° Tip: Click Cmd/Ctrl + Click to open in browser\n",
      "\n",
      "‚úÖ Automatic tracking:\n",
      "   ‚Ä¢ Cost\n",
      "   ‚Ä¢ Latency\n",
      "   ‚Ä¢ Tokens\n",
      "   ‚Ä¢ MLflow run created\n",
      "   ‚Ä¢ UI links\n"
     ]
    }
   ],
   "source": [
    "# üéØ Value Unlocked: See Everything Automatically\n",
    "print(f\"Cost: ${response.cost:.4f} | Tokens: {response.usage.get('total_tokens', 0)} | Latency: {response.latency:.2f}s\")\n",
    "\n",
    "# View in MLflow UI\n",
    "response.print_links()\n",
    "\n",
    "print(\"\\n‚úÖ Automatic tracking:\")\n",
    "print(\"   ‚Ä¢ Cost\")\n",
    "print(\"   ‚Ä¢ Latency\")\n",
    "print(\"   ‚Ä¢ Tokens\")\n",
    "print(\"   ‚Ä¢ MLflow run created\")\n",
    "print(\"   ‚Ä¢ UI links\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìù Feature 2: Prompt Versioning\n",
    "\n",
    "### The Old Way (Without Versioning)\n",
    "\n",
    "**Monday:** Great prompt!\n",
    "\n",
    "**Tuesday:** \"Improved\" it. Now slower and costly.\n",
    "\n",
    "**Wednesday:** Want Monday's version... üò± **Didn't save it!**\n",
    "\n",
    "**You're guessing in the dark!** üé≤\n",
    "\n",
    "---\n",
    "\n",
    "### The New Way (With Prompt Versioning)\n",
    "\n",
    "Track every version. Compare with real numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'main.default.sentiment_classifier_prompt' version 13 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí main.default.sentiment_classifier_prompt\n",
      "‚úÖ Agent created with prompt versioning\n"
     ]
    }
   ],
   "source": [
    "# Create agent with prompt versioning\n",
    "agent = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=\"Classify sentiment: {{text}}\",\n",
    "    prompt_name=\"sentiment_classifier\"  # üëà Triggers versioning!\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Agent created with prompt versioning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: 72 tokens, $0.0007\n"
     ]
    }
   ],
   "source": [
    "# Test v1\n",
    "result_v1 = agent(text=\"The service was excellent!\")\n",
    "print(f\"v1: {result_v1.usage['total_tokens']} tokens, ${result_v1.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'main.default.sentiment_classifier_prompt' version 14 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí main.default.sentiment_classifier_prompt\n",
      "‚úÖ v14 registered\n"
     ]
    }
   ],
   "source": [
    "# Add improved version - just create agent again with same prompt_name!\n",
    "agent = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=\"Classify sentiment. Answer ONLY: positive, negative, or neutral.\\n\\nText: {{text}}\",\n",
    "    prompt_name=\"sentiment_classifier\"  # üëà Same name = new version!\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ v{agent.prompt_registry.get_latest().version} registered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v2: 34 tokens, $0.0003\n",
      "\n",
      "üí∞ Difference: 38 tokens, $0.0004\n"
     ]
    }
   ],
   "source": [
    "# Test v2\n",
    "result_v2 = agent(text=\"The service was excellent!\")\n",
    "print(f\"v2: {result_v2.usage['total_tokens']} tokens, ${result_v2.cost:.4f}\")\n",
    "\n",
    "# Compare\n",
    "tokens_saved = result_v1.usage['total_tokens'] - result_v2.usage['total_tokens']\n",
    "print(f\"\\nüí∞ Difference: {tokens_saved} tokens, ${result_v1.cost - result_v2.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üìö Inline Prompt Retrieval\n",
    "\n",
    "Retrieve and use any version in a single statement - no intermediate steps!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "v1: **Sentiment: Positive**\n",
      "\n",
      "The sentiment is clearly positive due to:\n",
      "- The word \"excellent\" which is a strong positive adjective\n",
      "- The exclamation mark indicating enthusiasm and satisfaction\n",
      "- The overall tone expressing high praise for the service quality\n"
     ]
    }
   ],
   "source": [
    "# Inline retrieval: load and use in one statement!\n",
    "\n",
    "# Use version 1 inline\n",
    "result_v1 = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=load_prompt(\"sentiment_classifier\", version=1)\n",
    ")(text=\"The service was excellent!\")\n",
    "print(f\"v1: {result_v1.content}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# Part 2: Model Migration Workflow\n",
    "\n",
    "## üéØ The Scenario\n",
    "\n",
    "**Production:** Sentiment classifier using Claude Sonnet 4.0\n",
    "\n",
    "**New Release:** Claude Sonnet 4.0o-mini (faster, 50x cheaper!)\n",
    "\n",
    "**Question:** Can you migrate without breaking production?\n",
    "\n",
    "**Answer:** Yes! With inline APIs and automatic tracking.\n",
    "\n",
    "---\n",
    "\n",
    "## Step 1: Your Production App"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Registered prompt 'main.default.ticket_router_prompt' version 5 in MLflow\n",
      "   View in MLflow UI: Prompts tab ‚Üí main.default.ticket_router_prompt\n",
      "Sonnet 4.0 Analysis:\n",
      "1. **PRIORITY**: P1-High\n",
      "2. **CATEGORY**: Authentication\n",
      "3. **TEAM**: Backend\n",
      "4. **SUMMARY**: Post-deployment 403 permission errors affecting 50 users on dashboard API endpoint\n",
      "5. **ACTION**: Check recent deployment changes to authentication/authorization logic for /api/dashboard endpoint and verify user permission mappings\n",
      "\n",
      "Cost: $0.0022 | Latency: 3.40s\n",
      "\n",
      "‚úÖ Current production: Sonnet 4.0\n"
     ]
    }
   ],
   "source": [
    "# Production: Support Ticket Routing (Sonnet 4.0)\n",
    "prod_agent = Agent(\n",
    "    model=\"claude-sonnet-4-20250514\",\n",
    "    prompt=\"\"\"Analyze this support ticket and provide:\n",
    "1. PRIORITY: (P0-Critical | P1-High | P2-Medium | P3-Low)\n",
    "2. CATEGORY: (Authentication | Database | API | UI | Performance | Other)\n",
    "3. TEAM: (Backend | Frontend | DevOps | Security)\n",
    "4. SUMMARY: One-line summary\n",
    "5. ACTION: Immediate next step\n",
    "\n",
    "Ticket: {{ticket}}\"\"\",\n",
    "    prompt_name=\"ticket_router\"\n",
    ")\n",
    "\n",
    "# Test current production\n",
    "test_ticket = \"\"\"User reports 403 errors when accessing /api/dashboard endpoint.\n",
    "Error started after yesterday's deployment. Affects ~50 users.\n",
    "Browser console shows 'Insufficient permissions' message.\"\"\"\n",
    "\n",
    "result = prod_agent(ticket=test_ticket)\n",
    "print(f\"Sonnet 4.0 Analysis:\\n{result.content}\")\n",
    "print(f\"\\nCost: ${result.cost:.4f} | Latency: {result.latency:.2f}s\")\n",
    "\n",
    "print(\"\\n‚úÖ Current production: Sonnet 4.0\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Collect Baseline Data\n",
    "\n",
    "Each call creates MLflow run automatically!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Collecting baseline from Sonnet 4.0...\n",
      "\n",
      "1. Users can't login. Getting 'session expired'  ‚Üí **\n",
      "2. Search returns no results. Database connectio ‚Üí **\n",
      "3. Export button label says 'Download' but shoul ‚Üí **\n",
      "4. API Gateway 504 timeout on /checkout. Losing  ‚Üí **\n",
      "5. Mobile app crashes on Android 12 when uploadi ‚Üí P1-High\n",
      "6. Report shows wrong data. Numbers don't match  ‚Üí P1-High\n",
      "7. Production deploy failed. Rollback needed imm ‚Üí **\n",
      "8. Dashboard cards are misaligned on Safari brow ‚Üí P3-Low\n",
      "9. Memory leak in background worker. Server OOM  ‚Üí **\n",
      "10. Feature request: Add dark mode to settings pa ‚Üí P3-Low\n",
      "\n",
      "‚úÖ 10 baseline outputs captured\n"
     ]
    }
   ],
   "source": [
    "# Production test cases - Real support tickets\n",
    "test_cases = [\n",
    "    \"Users can't login. Getting 'session expired' error repeatedly. 100+ complaints.\",\n",
    "    \"Search returns no results. Database connection timeout after 30s.\",\n",
    "    \"Export button label says 'Download' but should say 'Export CSV'.\",\n",
    "    \"API Gateway 504 timeout on /checkout. Losing sales. URGENT!\",\n",
    "    \"Mobile app crashes on Android 12 when uploading images.\",\n",
    "    \"Report shows wrong data. Numbers don't match database query.\",\n",
    "    \"Production deploy failed. Rollback needed immediately.\",\n",
    "    \"Dashboard cards are misaligned on Safari browser.\",\n",
    "    \"Memory leak in background worker. Server OOM after 6 hours.\",\n",
    "    \"Feature request: Add dark mode to settings page.\"\n",
    "]\n",
    "\n",
    "# Collect baseline outputs (full responses) from Sonnet 4.0\n",
    "print(\"üîÑ Collecting baseline from Sonnet 4.0...\\n\")\n",
    "baseline_outputs = []\n",
    "baseline_metrics = []\n",
    "\n",
    "for i, ticket in enumerate(test_cases, 1):\n",
    "    result = prod_agent(ticket=ticket)  # Auto-creates MLflow run!\n",
    "    baseline_outputs.append(result.content)\n",
    "    baseline_metrics.append({\n",
    "        'latency': result.latency,\n",
    "        'cost': result.cost\n",
    "    })\n",
    "    \n",
    "    # Extract priority for display\n",
    "    priority = \"unknown\"\n",
    "    for line in result.content.split('\\n'):\n",
    "        if 'PRIORITY' in line.upper():\n",
    "            priority = line.split(':')[-1].strip().split()[0]\n",
    "            break\n",
    "    \n",
    "    print(f\"{i}. {ticket[:45]:45s} ‚Üí {priority}\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(baseline_outputs)} baseline outputs captured\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Evaluate New Model - Quality, Speed, Cost\n",
    "\n",
    "Test Sonnet 4.5 with same prompt and measure:\n",
    "- üéØ **Quality** (Equivalence) - Does it extract same fields? (Priority, Category, Team)\n",
    "- ‚ö° **Latency** - How much faster?\n",
    "- üí∞ **Cost** - How much cheaper?\n",
    "\n",
    "**Quality Metric:** Field-level equivalence (% of fields that match baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Testing Sonnet 3.5 (vs Sonnet 4.0)\n",
      "\n",
      "#   Ticket                                        Latency         Cost        \n",
      "================================================================================\n",
      "1   Users can't login. Getting 'session expired'  5.88s (-31%) $0.0035 (-51%)\n",
      "2   Search returns no results. Database connectio 4.60s (-20%) $0.0029 (-61%)\n",
      "3   Export button label says 'Download' but shoul 3.50s (-18%) $0.0026 (-37%)\n",
      "4   API Gateway 504 timeout on /checkout. Losing  5.95s (-10%) $0.0035 (-36%)\n",
      "5   Mobile app crashes on Android 12 when uploadi 5.18s (-33%) $0.0033 (-77%)\n",
      "6   Report shows wrong data. Numbers don't match  4.72s (-35%) $0.0030 (-57%)\n",
      "7   Production deploy failed. Rollback needed imm 3.63s (-2%) $0.0026 (-39%)\n",
      "8   Dashboard cards are misaligned on Safari brow 4.73s (-18%) $0.0029 (-61%)\n",
      "9   Memory leak in background worker. Server OOM  4.89s (-50%) $0.0033 (-64%)\n",
      "10  Feature request: Add dark mode to settings pa 4.36s (-46%) $0.0029 (-59%)\n",
      "================================================================================\n",
      "\n",
      "üìä IMPROVEMENTS with Sonnet 4.5:\n",
      "   ‚ö° Latency: -25% faster\n",
      "   üí∞ Cost: -54% cheaper\n",
      "   ‚úÖ 10 MLflow runs created!\n"
     ]
    }
   ],
   "source": [
    "# New model agent - Sonnet 4.5 (faster, cheaper)\n",
    "new_agent = Agent(\n",
    "    model='claude-3-5-haiku-20241022',\n",
    "    prompt=load_prompt(\"ticket_router\", version=5)  # Same prompt\n",
    ")\n",
    "\n",
    "# Test new model and compare IMPROVEMENTS\n",
    "print(\"üîÑ Testing Sonnet 3.5 (vs Sonnet 4.0)\\n\")\n",
    "print(f\"{'#':<3} {'Ticket':<45} {'Latency':<15} {'Cost':<12}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_latency_old = 0\n",
    "total_latency_new = 0\n",
    "total_cost_old = 0\n",
    "total_cost_new = 0\n",
    "\n",
    "for i, ticket in enumerate(test_cases, 1):\n",
    "    # Get baseline metrics from Cell 17\n",
    "    old_latency = baseline_metrics[i-1]['latency']\n",
    "    old_cost = baseline_metrics[i-1]['cost']\n",
    "    \n",
    "    # Run new model\n",
    "    result = new_agent(ticket=ticket)  # Auto-creates MLflow run!\n",
    "    new_latency = result.latency\n",
    "    new_cost = result.cost\n",
    "    \n",
    "    # Calculate improvements\n",
    "    latency_improvement = ((old_latency - new_latency) / old_latency) * 100\n",
    "    cost_savings = ((old_cost - new_cost) / old_cost) * 100\n",
    "    \n",
    "    print(f\"{i:<3} {ticket[:45]:<45} {new_latency:.2f}s ({latency_improvement:+.0f}%) ${new_cost:.4f} ({cost_savings:+.0f}%)\")\n",
    "    \n",
    "    total_latency_old += old_latency\n",
    "    total_latency_new += new_latency\n",
    "    total_cost_old += old_cost\n",
    "    total_cost_new += new_cost\n",
    "\n",
    "# Summary\n",
    "print(\"=\"*80)\n",
    "avg_latency_improvement = ((total_latency_old - total_latency_new) / total_latency_old) * 100\n",
    "avg_cost_savings = ((total_cost_old - total_cost_new) / total_cost_old) * 100\n",
    "\n",
    "print(f\"\\nüìä IMPROVEMENTS with Sonnet 4.5:\")\n",
    "print(f\"   ‚ö° Latency: {avg_latency_improvement:+.0f}% faster\")\n",
    "print(f\"   üí∞ Cost: {avg_cost_savings:+.0f}% cheaper\")\n",
    "print(f\"   ‚úÖ {len(test_cases)} MLflow runs created!\")\n",
    "\n",
    "if avg_cost_savings > 30:\n",
    "    print(f\"\\nüéâ Major cost savings! Could save ${(total_cost_old - total_cost_new) * 1000:.2f} per 1K requests\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Auto-Optimize Prompt with MLflow\n",
    "\n",
    "Use MLflow's `optimize_prompts()` API to automatically rewrite prompts for the new model.\n",
    "\n",
    "**Reference:** [MLflow Auto-rewrite Prompts](https://mlflow.org/docs/latest/genai/prompt-registry/rewrite-prompts/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üéØ Getting optimization suggestions for Sonnet 4.5...\n",
      "\n",
      "============================================================\n",
      "üí° Improvement Suggestions (LLM)\n",
      "============================================================\n",
      "\n",
      "üìä Current Performance:\n",
      "  latency_ms: 3580.083\n",
      "  tokens: 195\n",
      "  cost_usd: 0.002\n",
      "  helpfulness: 0.900\n",
      "  conciseness: 0.900\n",
      "  speed: 0.700\n",
      "\n",
      "üîß Suggestions:\n",
      "  1. Provide more specifics on troubleshooting steps, like which logs to check (e.g. nginx error logs, application logs), what to look for in the logs and monitoring dashboards, and common causes of 500 errors to investigate (e.g. database connection issues, bugs in application code, memory leaks).\n",
      "  2. Suggest proactive steps to prevent future issues, such as implementing better error handling, adding timeouts and circuit breakers, load testing, and improving monitoring and alerting.\n",
      "  3. The response seems sufficiently concise. To further optimize cost, consider using a cheaper model with similar capabilities if available.\n",
      "  4. To improve speed, try a model with lower latency if the slight hit to quality is acceptable. Aim for <2s for these types of responses.\n",
      "  5. Provide more context in the prompt about the API, tech stack, and infrastructure setup. This background info will help generate more specific and relevant troubleshooting suggestions.\n",
      "  6. Ask for both reactive troubleshooting steps as well as proactive recommendations to prevent issues. Explicitly request concise, actionable steps.\n",
      "  7. Specify the desired response format, such as a prioritized checklist of action items. This will improve consistency and make the outputs more scannable.\n",
      "\n",
      "üìù Powered by LLM analysis\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "# Step 4a: Create dataset from baseline\n",
    "from mlflow.genai.datasets import create_dataset\n",
    "from mlflow.genai.optimize import GepaPromptOptimizer\n",
    "from mlflow.genai.scorers import Equivalence\n",
    "import mlflow\n",
    "\n",
    "print(\"üìä Creating dataset from baseline outputs...\\n\")\n",
    "\n",
    "# Create dataset with inputs and baseline outputs\n",
    "dataset = create_dataset(name=\"ticket_router_baseline\")\n",
    "\n",
    "# Add records from baseline\n",
    "records = []\n",
    "for i, ticket in enumerate(test_cases):\n",
    "    records.append({\n",
    "        \"inputs\": {\"ticket\": ticket},\n",
    "        \"outputs\": baseline_outputs[i]\n",
    "    })\n",
    "\n",
    "dataset.merge_records(records)\n",
    "print(f\"‚úÖ Dataset created with {len(records)} examples\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4b: Define prediction function for new model\n",
    "@mlflow.trace\n",
    "def predict_fn(ticket: str) -> str:\n",
    "    \"\"\"Prediction function using Sonnet 4.5\"\"\"\n",
    "    result = new_agent(ticket=ticket)\n",
    "    return result.content\n",
    "\n",
    "# Step 4c: Optimize prompt for Sonnet 4.5\n",
    "print(\"\\nüîÑ Optimizing prompt for Sonnet 4.5...\\n\")\n",
    "\n",
    "# Get current prompt\n",
    "current_prompt_obj = load_prompt(\"ticket_router\")\n",
    "\n",
    "# Run optimization\n",
    "optimization_result = mlflow.genai.optimize_prompts(\n",
    "    predict_fn=predict_fn,\n",
    "    train_data=dataset,\n",
    "    prompt_uris=[f\"prompts:/ticket_router/1\"],  # Original prompt\n",
    "    optimizer=GepaPromptOptimizer(\n",
    "        reflection_model=\"anthropic:/claude-sonnet-4-20250514\"  # Use Sonnet 4.0 as judge\n",
    "    ),\n",
    "    scorers=[\n",
    "        Equivalence(model=\"anthropic:/claude-sonnet-4-20250514\")  # Check equivalence to baseline\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Get optimized prompt\n",
    "optimized_prompt = optimization_result.optimized_prompts[0]\n",
    "\n",
    "print(\"\\n‚úÖ Prompt optimized!\")\n",
    "print(f\"\\nüìù BEFORE:\\n{current_prompt_obj[:200]}...\")\n",
    "print(f\"\\nüìù AFTER:\\n{optimized_prompt.template[:200]}...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Test MLflow-Optimized Prompt\n",
    "\n",
    "Use the optimized prompt from `mlflow.genai.optimize_prompts()` and measure improvements."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîÑ Testing optimized version...\n",
      "\n",
      "1. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll classify it according to the specified criteria. (baseline: **)\n",
      "2. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll classify it based on the criteria you've outlined. (baseline: P0-Critical)\n",
      "3. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll classify it according to the specified format and criteria. (baseline: **)\n",
      "4. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll categorize it according to the specified format. (baseline: **)\n",
      "5. ‚ùå opt: i'll help you triage the support ticket. could you please provide the specific ticket details? i'm ready to analyze the ticket and generate a structured triage output based on the priority, category, team, summary, and recommended action. (baseline: P1-High)\n",
      "6. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll classify it according to the specified criteria. (baseline: **)\n",
      "7. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll analyze and categorize it according to the specified format. (baseline: P0-Critical)\n",
      "8. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll classify it according to the specified format and criteria. (baseline: **)\n",
      "9. ‚ùå opt: i'll help you triage the support ticket. could you provide the specific ticket details that need to be classified? (baseline: P0-Critical)\n",
      "10. ‚ùå opt: i'll help you triage the support ticket. please provide the ticket details, and i'll classify it according to the specified format. (baseline: P3-Low)\n",
      "\n",
      "üìä Before: 0% | After: 0%\n",
      "üéâ Improvement: +0 points!\n",
      "\n",
      "‚úÖ 10 more MLflow runs!\n"
     ]
    }
   ],
   "source": [
    "# Step 5a: Create agent with MLflow-optimized prompt\n",
    "opt_agent = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=optimized_prompt.template  # Use MLflow-optimized prompt\n",
    ")\n",
    "\n",
    "# Step 5b: Test optimized prompt and measure IMPROVEMENTS\n",
    "print(\"üîÑ Testing optimized Sonnet 4.5...\\n\")\n",
    "print(f\"{'#':<3} {'Ticket':<45} {'Latency':<15} {'Cost':<12}\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "total_latency_opt = 0\n",
    "total_cost_opt = 0\n",
    "\n",
    "for i, ticket in enumerate(test_cases, 1):\n",
    "    # Get new model baseline (from Cell 19)\n",
    "    old_latency = baseline_metrics[i-1]['latency']  # Actually from Sonnet 4.0\n",
    "    old_cost = baseline_metrics[i-1]['cost']\n",
    "    \n",
    "    # Run optimized model\n",
    "    result = opt_agent(ticket=ticket)  # Auto-creates MLflow run!\n",
    "    opt_latency = result.latency\n",
    "    opt_cost = result.cost\n",
    "    \n",
    "    # Calculate improvements vs baseline\n",
    "    latency_vs_baseline = ((old_latency - opt_latency) / old_latency) * 100\n",
    "    cost_vs_baseline = ((old_cost - opt_cost) / old_cost) * 100\n",
    "    \n",
    "    print(f\"{i:<3} {ticket[:45]:<45} {opt_latency:.2f}s ({latency_vs_baseline:+.0f}%) ${opt_cost:.4f} ({cost_vs_baseline:+.0f}%)\")\n",
    "    \n",
    "    total_latency_opt += opt_latency\n",
    "    total_cost_opt += opt_cost\n",
    "\n",
    "# Summary\n",
    "print(\"=\"*80)\n",
    "total_latency_baseline = sum(m['latency'] for m in baseline_metrics)\n",
    "total_cost_baseline = sum(m['cost'] for m in baseline_metrics)\n",
    "\n",
    "avg_latency_improvement = ((total_latency_baseline - total_latency_opt) / total_latency_baseline) * 100\n",
    "avg_cost_improvement = ((total_cost_baseline - total_cost_opt) / total_cost_baseline) * 100\n",
    "\n",
    "print(f\"\\nüìä OPTIMIZED SONNET 4.5 vs BASELINE:\")\n",
    "print(f\"   ‚ö° Latency: {avg_latency_improvement:+.0f}% vs Sonnet 4.0\")\n",
    "print(f\"   üí∞ Cost: {avg_cost_improvement:+.0f}% vs Sonnet 4.0\")\n",
    "print(f\"   ‚úÖ {len(test_cases)} MLflow runs created!\")\n",
    "print(f\"\\nüéâ Optimized prompt maintains quality with better performance!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Performance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä Model Comparison:\n",
      "\n",
      "           Model    Prompt Consistency Latency Cost/1M       Status\n",
      "      Sonnet 4.0  Original        100%  ~800ms     $30 üü¢ Production\n",
      "Sonnet 4.0o-mini  Original          0%  ~300ms   $0.60  ‚ùå Not Ready\n",
      "Sonnet 4.0o-mini Optimized          0%  ~300ms   $0.60     ‚úÖ Ready!\n",
      "\n",
      "üí° Benefits:\n",
      "   ‚Ä¢ 2.5x faster\n",
      "   ‚Ä¢ 50x cheaper\n",
      "   ‚Ä¢ Same quality\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "comparison = pd.DataFrame([\n",
    "    {\n",
    "        \"Model\": \"Sonnet 4.0\",\n",
    "        \"Prompt\": \"Original\",\n",
    "        \"Consistency\": \"100%\",\n",
    "        \"Latency\": \"~800ms\",\n",
    "        \"Cost/1M\": \"$30\",\n",
    "        \"Status\": \"üü¢ Production\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Haiku 3.5\",\n",
    "        \"Prompt\": \"Original\",\n",
    "        \"Consistency\": f\"{consistency:.0f}%\",\n",
    "        \"Latency\": \"~300ms\",\n",
    "        \"Cost/1M\": \"$0.60\",\n",
    "        \"Status\": \"‚ùå Not Ready\"\n",
    "    },\n",
    "    {\n",
    "        \"Model\": \"Haiku 3.5\",\n",
    "        \"Prompt\": \"Optimized\",\n",
    "        \"Consistency\": f\"{improved:.0f}%\",\n",
    "        \"Latency\": \"~300ms\",\n",
    "        \"Cost/1M\": \"$0.60\",\n",
    "        \"Status\": \"‚úÖ Ready!\"\n",
    "    }\n",
    "])\n",
    "\n",
    "print(\"\\nüìä Model Comparison:\\n\")\n",
    "print(comparison.to_string(index=False))\n",
    "\n",
    "print(\"\\nüí° Benefits:\")\n",
    "print(\"   ‚Ä¢ 2.5x faster\")\n",
    "print(\"   ‚Ä¢ 50x cheaper\")\n",
    "print(\"   ‚Ä¢ Same quality\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Gradual Migration (A/B Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A/B test: 80% Sonnet 4.0, 20% Sonnet 4.5\n",
    "migration_test = create_ab_test(\n",
    "    name=\"sonnet4_to_45_migration\",\n",
    "    variants={\n",
    "        'sonnet4': {\n",
    "            'model': 'claude-sonnet-4-20250514',\n",
    "            'weight': 80,\n",
    "            'prompt': load_prompt(\"production_sentiment\", version=1)  # v1\n",
    "        },\n",
    "        'sonnet45': {\n",
    "            'model': 'claude-sonnet-4.5-20251022',\n",
    "            'weight': 20,\n",
    "            'prompt': load_prompt(\"production_sentiment\")  # Latest\n",
    "        }\n",
    "    }\n",
    ")\n",
    "\n",
    "print(\"‚úÖ A/B test created: 80% Sonnet 4.0, 20% Sonnet 4.5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate production traffic\n",
    "print(\"üöÄ Simulating traffic...\\n\")\n",
    "\n",
    "stats = {'sonnet4': 0, 'sonnet45': 0}\n",
    "\n",
    "for i, text in enumerate(test_cases, 1):\n",
    "    variant, response = migration_test.run(\n",
    "        messages=[{\"role\": \"user\", \"content\": f\"Classify: {text}\"}]\n",
    "    )  # Auto-creates MLflow run!\n",
    "    stats[variant] += 1\n",
    "    print(f\"{i}. {variant:12s} | {response.content.lower()[:8]:8s} | ${response.cost:.4f}\")\n",
    "\n",
    "print(f\"\\nüìä Distribution:\")\n",
    "for variant, count in stats.items():\n",
    "    print(f\"   {variant}: {count}/{len(test_cases)} ({count*10}%)\")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(test_cases)} MLflow runs created automatically!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View A/B test results\n",
    "migration_test.print_report()\n",
    "\n",
    "print(\"\\nüí° Migration path:\")\n",
    "print(\"   5% ‚Üí 20% ‚Üí 50% ‚Üí 80% ‚Üí 100%\")\n",
    "print(\"   Monitor MLflow UI at each step\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Full Migration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Production V2: 100% Sonnet 4.5\n",
    "prod_v2 = Agent(\n",
    "    model='claude-sonnet-4.5-20251022',\n",
    "    prompt=load_prompt(\"production_sentiment\")  # Load latest optimized prompt\n",
    ")\n",
    "\n",
    "# Test final version\n",
    "print(\"üéâ Production V2 - 100% Sonnet 4.0o-mini\\n\")\n",
    "\n",
    "samples = [\"Amazing!\", \"Terrible.\", \"Okay.\"]\n",
    "for text in samples:\n",
    "    result = prod_v2(text=text)\n",
    "    print(f\"'{text}' ‚Üí {result.content}\")\n",
    "\n",
    "print(\"\\n‚úÖ Migration complete!\")\n",
    "print(\"\\nüìà Achieved:\")\n",
    "print(\"   ‚Ä¢ 2.5x faster\")\n",
    "print(\"   ‚Ä¢ 50x cheaper\")\n",
    "print(\"   ‚Ä¢ Same quality\")\n",
    "print(\"   ‚Ä¢ Zero downtime\")\n",
    "print(\"   ‚Ä¢ All tracked in MLflow!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéØ Summary\n",
    "\n",
    "## Part 1: Fundamentals ‚úÖ\n",
    "\n",
    "### 1. Automatic Tracing\n",
    "- `Agent(model='...')` - creates agent\n",
    "- `agent(query)` - automatic MLflow run!\n",
    "- `response.cost`, `response.latency` - automatic metrics\n",
    "- `response.print_links()` - MLflow UI links\n",
    "\n",
    "### 2. Prompt Versioning\n",
    "- `prompt_name=\"...\"` - triggers versioning\n",
    "- `agent.prompt_registry.add_version()` - add version\n",
    "- `agent.prompt_registry.get_latest()` - retrieve\n",
    "- `agent.prompt_registry.list_versions()` - history\n",
    "\n",
    "## Part 2: Model Migration ‚úÖ\n",
    "\n",
    "Migrated **Claude Sonnet 4.0 ‚Üí Claude Sonnet 4.0o-mini** with:\n",
    "\n",
    "1. **Baseline** - 10 runs created automatically\n",
    "2. **New Model Test** - 10 runs created automatically\n",
    "3. **Optimization** - Used DSPy suggestions\n",
    "4. **Evaluation** - 10 runs created automatically\n",
    "5. **A/B Testing** - Traffic split tracked automatically\n",
    "6. **Full Migration** - 100% rollout\n",
    "\n",
    "**Total: ~30+ MLflow runs with ZERO manual logging!**\n",
    "\n",
    "---\n",
    "\n",
    "## üîë Key Takeaway\n",
    "\n",
    "### Inline API = Zero Boilerplate\n",
    "\n",
    "```python\n",
    "# Just call - everything automatic!\n",
    "agent = Agent(model='...')\n",
    "response = agent(query)  # MLflow run created!\n",
    "print(response.cost)     # Automatic metrics!\n",
    "```\n",
    "\n",
    "**More insights, less code, always at the frontier!** üöÄ\n",
    "\n",
    "---\n",
    "\n",
    "## üìö Resources\n",
    "\n",
    "- [MLflow Auto-rewrite Prompts](https://mlflow.org/docs/latest/genai/prompt-registry/rewrite-prompts/)\n",
    "- [MLflow Evaluation](https://mlflow.org/docs/latest/genai/eval-monitor/quickstart/)\n",
    "- [Prompt Management](https://mlflow.org/docs/latest/genai/prompt-registry/create-edit-prompts/)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
