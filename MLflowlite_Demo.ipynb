{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mlflowlite Demo\n",
    "\n",
    "Four features. Zero config.\n",
    "\n",
    "1. **Automatic Tracing** - Every LLM call logged to MLflow\n",
    "2. **Prompt Versioning** - Git-like version control for prompts\n",
    "3. **AI Optimization** - Get specific improvement suggestions\n",
    "4. **Reliability** - Retry, timeout, and fallback support\n",
    "\n",
    "---\n",
    "\n",
    "## Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üìã Table of Contents\n",
    "\n",
    "1. [Setup](#setup)\n",
    "2. [The Scenario](#the-scenario)\n",
    "3. [Feature 1: Automatic Tracing](#feature-1-automatic-tracing)\n",
    "4. [Feature 2: Prompt Management & Versioning](#feature-2-prompt-management--versioning)\n",
    "5. [Feature 3: DSPy-Style Optimization](#feature-3-dspy-style-optimization)\n",
    "6. [Feature 4: Reliability Features](#feature-4-reliability-features)\n",
    "7. [What You Just Learned](#what-you-just-learned)\n",
    "8. [Advanced: Smart Routing & A/B Testing](#advanced-smart-routing--ab-testing)\n",
    "9. [Next Steps](#next-steps)\n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "MlflowException",
     "evalue": "Experiment 'ai_gateway_queries' already exists in deleted state. You can restore the experiment, or permanently delete the experiment from the .trash folder (under tracking server's root folder) in order to use this experiment name again.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[0;32m~/Desktop/gateway-oss/mlflowlite/simple_api.py:61\u001b[0m, in \u001b[0;36mSimpleAPI.__init__\u001b[0;34m(self, tracking_uri)\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m---> 61\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mset_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai_gateway_queries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/venv/lib/python3.9/site-packages/mlflow/tracking/fluent.py:209\u001b[0m, in \u001b[0;36mset_experiment\u001b[0;34m(experiment_name, experiment_id)\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mlifecycle_stage \u001b[38;5;241m!=\u001b[39m LifecycleStage\u001b[38;5;241m.\u001b[39mACTIVE:\n\u001b[0;32m--> 209\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    210\u001b[0m             message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m    211\u001b[0m                 \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot set a deleted experiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m as the active\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    212\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m experiment. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    213\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can restore the experiment, or permanently delete the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    214\u001b[0m                 \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mexperiment to create a new one.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    215\u001b[0m             ),\n\u001b[1;32m    216\u001b[0m             error_code\u001b[38;5;241m=\u001b[39mINVALID_PARAMETER_VALUE,\n\u001b[1;32m    217\u001b[0m         )\n\u001b[1;32m    219\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m _active_experiment_id\n",
      "\u001b[0;31mMlflowException\u001b[0m: Cannot set a deleted experiment 'ai_gateway_queries' as the active experiment. You can restore the experiment, or permanently delete the experiment to create a new one.",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mMlflowException\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m load_dotenv()\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Import LiteLLM-style API\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflowlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmla\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflowlite\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Agent\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Setup complete!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/mlflowlite/__init__.py:36\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflowlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mrouting\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     28\u001b[0m     smart_query,\n\u001b[1;32m     29\u001b[0m     create_ab_test,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     32\u001b[0m     RoutingDecision,\n\u001b[1;32m     33\u001b[0m )\n\u001b[1;32m     35\u001b[0m \u001b[38;5;66;03m# Simple notebook-style API (alternative - legacy, for backwards compatibility)\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmlflowlite\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msimple_api\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     37\u001b[0m     ai_query,\n\u001b[1;32m     38\u001b[0m     compare_models,\n\u001b[1;32m     39\u001b[0m     QueryResult,\n\u001b[1;32m     40\u001b[0m )\n\u001b[1;32m     42\u001b[0m __version__ \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m0.1.0\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     43\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# Core classes\u001b[39;00m\n\u001b[1;32m     45\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAgent\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mQueryResult\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     74\u001b[0m ]\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/mlflowlite/simple_api.py:483\u001b[0m\n\u001b[1;32m    479\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquery_history[\u001b[38;5;241m-\u001b[39mn:]\n\u001b[1;32m    482\u001b[0m \u001b[38;5;66;03m# Global instance for convenience\u001b[39;00m\n\u001b[0;32m--> 483\u001b[0m _api_instance \u001b[38;5;241m=\u001b[39m \u001b[43mSimpleAPI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    486\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mai_query\u001b[39m(\n\u001b[1;32m    487\u001b[0m     model: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m    488\u001b[0m     prompt: \u001b[38;5;28mstr\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    493\u001b[0m     print_summary: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    494\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m QueryResult:\n\u001b[1;32m    495\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    496\u001b[0m \u001b[38;5;124;03m    Simple AI query function - notebook-friendly interface.\u001b[39;00m\n\u001b[1;32m    497\u001b[0m \u001b[38;5;124;03m    \u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    515\u001b[0m \u001b[38;5;124;03m        >>> result.print_summary()\u001b[39;00m\n\u001b[1;32m    516\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/mlflowlite/simple_api.py:63\u001b[0m, in \u001b[0;36mSimpleAPI.__init__\u001b[0;34m(self, tracking_uri)\u001b[0m\n\u001b[1;32m     61\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai_gateway_queries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     62\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m---> 63\u001b[0m     \u001b[43mmlflow\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mai_gateway_queries\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m     mlflow\u001b[38;5;241m.\u001b[39mset_experiment(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mai_gateway_queries\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     66\u001b[0m \u001b[38;5;66;03m# Cache for query results (for comparison)\u001b[39;00m\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/venv/lib/python3.9/site-packages/mlflow/tracking/fluent.py:2066\u001b[0m, in \u001b[0;36mcreate_experiment\u001b[0;34m(name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   2018\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m   2019\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   2020\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2021\u001b[0m     tags: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   2022\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   2023\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;124;03m    Create an experiment.\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2064\u001b[0m \u001b[38;5;124;03m        Creation timestamp: 1662004217511\u001b[39;00m\n\u001b[1;32m   2065\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2066\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mMlflowClient\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/venv/lib/python3.9/site-packages/mlflow/tracking/client.py:1801\u001b[0m, in \u001b[0;36mMlflowClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m   1749\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcreate_experiment\u001b[39m(\n\u001b[1;32m   1750\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   1751\u001b[0m     name: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m   1752\u001b[0m     artifact_location: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1753\u001b[0m     tags: Optional[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1754\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m:\n\u001b[1;32m   1755\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m   1756\u001b[0m \n\u001b[1;32m   1757\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1799\u001b[0m \n\u001b[1;32m   1800\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1801\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_tracking_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/venv/lib/python3.9/site-packages/mlflow/tracking/_tracking_service/client.py:275\u001b[0m, in \u001b[0;36mTrackingServiceClient.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    261\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Create an experiment.\u001b[39;00m\n\u001b[1;32m    262\u001b[0m \n\u001b[1;32m    263\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    272\u001b[0m \n\u001b[1;32m    273\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    274\u001b[0m _validate_experiment_artifact_location(artifact_location)\n\u001b[0;32m--> 275\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstore\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_experiment\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    276\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    277\u001b[0m \u001b[43m    \u001b[49m\u001b[43martifact_location\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43martifact_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    278\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mExperimentTag\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtags\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    279\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:438\u001b[0m, in \u001b[0;36mFileStore.create_experiment\u001b[0;34m(self, name, artifact_location, tags)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m artifact_location:\n\u001b[1;32m    436\u001b[0m     _validate_experiment_artifact_location_length(artifact_location)\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_experiment_does_not_exist\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    439\u001b[0m experiment_id \u001b[38;5;241m=\u001b[39m _generate_unique_integer_id()\n\u001b[1;32m    440\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_experiment_with_id(name, \u001b[38;5;28mstr\u001b[39m(experiment_id), artifact_location, tags)\n",
      "File \u001b[0;32m~/Desktop/gateway-oss/venv/lib/python3.9/site-packages/mlflow/store/tracking/file_store.py:418\u001b[0m, in \u001b[0;36mFileStore._validate_experiment_does_not_exist\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    416\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m experiment \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    417\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m experiment\u001b[38;5;241m.\u001b[39mlifecycle_stage \u001b[38;5;241m==\u001b[39m LifecycleStage\u001b[38;5;241m.\u001b[39mDELETED:\n\u001b[0;32m--> 418\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    419\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m!r}\u001b[39;00m\u001b[38;5;124m already exists in deleted state. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    420\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou can restore the experiment, or permanently delete the experiment \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    421\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfrom the .trash folder (under tracking server\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124ms root folder) in order to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    422\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse this experiment name again.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    423\u001b[0m             databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_ALREADY_EXISTS,\n\u001b[1;32m    424\u001b[0m         )\n\u001b[1;32m    425\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    426\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m MlflowException(\n\u001b[1;32m    427\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mExperiment \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mexperiment\u001b[38;5;241m.\u001b[39mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m already exists.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    428\u001b[0m             databricks_pb2\u001b[38;5;241m.\u001b[39mRESOURCE_ALREADY_EXISTS,\n\u001b[1;32m    429\u001b[0m         )\n",
      "\u001b[0;31mMlflowException\u001b[0m: Experiment 'ai_gateway_queries' already exists in deleted state. You can restore the experiment, or permanently delete the experiment from the .trash folder (under tracking server's root folder) in order to use this experiment name again."
     ]
    }
   ],
   "source": [
    "# Install if needed (uncomment if running for first time)\n",
    "# !pip install -e .\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Force reload module (fixes Cursor/VS Code notebook caching)\n",
    "import sys\n",
    "if 'mlflowlite' in sys.modules:\n",
    "    del sys.modules['mlflowlite']\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "# Import LiteLLM-style API\n",
    "import mlflowlite as mla\n",
    "from mlflowlite import Agent\n",
    "\n",
    "print(\"‚úÖ Setup complete!\")\n",
    "print(\"üì¶ Ready to demonstrate:\")\n",
    "print(\"   1Ô∏è‚É£  Automatic MLflow Tracing\")\n",
    "print(\"   2Ô∏è‚É£  Prompt Management & Versioning\")\n",
    "print(\"   3Ô∏è‚É£  DSPy-Style Optimization\")\n",
    "print(\"   4Ô∏è‚É£  Reliability Features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üìß The Scenario: A Support Ticket\n",
    "\n",
    "Imagine you're building a support bot. You get this ticket:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "support_ticket = \"\"\"\n",
    "Subject: Unable to access dashboard\n",
    "\n",
    "User reported that they cannot access the analytics dashboard.\n",
    "They receive a 403 Forbidden error when clicking on the dashboard link.\n",
    "User role: Manager\n",
    "Last successful access: 2 days ago\n",
    "Browser: Chrome 120\n",
    "\"\"\"\n",
    "\n",
    "print(\"üìã Sample Support Ticket:\")\n",
    "print(support_ticket)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìä Feature 1: Automatic Tracing\n",
    "\n",
    "## The Old Way (Without Tracing)\n",
    "\n",
    "You call an LLM:\n",
    "```python\n",
    "response = openai.chat.completions.create(...)\n",
    "print(response)\n",
    "```\n",
    "\n",
    "**Questions you can't answer:**\n",
    "- ‚ùì How much did that cost?\n",
    "- ‚ùì How long did it take?\n",
    "- ‚ùì Was the response quality good?\n",
    "- ‚ùì Can I compare this to yesterday's version?\n",
    "\n",
    "**You're flying blind! üõ©Ô∏èüí®**\n",
    "\n",
    "---\n",
    "\n",
    "## The New Way (With mlflowlite)\n",
    "\n",
    "**Same code, automatic insights:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a simple call - automatically traced!\n",
    "response1 = mla.query(\n",
    "    model='claude-3-5-sonnet',\n",
    "    prompt='Summarize this support ticket in 2 sentences',\n",
    "    input=support_ticket\n",
    ")\n",
    "\n",
    "print(\"‚úÖ Response:\")\n",
    "print(response1.content)\n",
    "print(\"\\n\" + \"=\"*70)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ Value Unlocked: See Everything Automatically\n",
    "\n",
    "**Look what you get for FREE:**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View automatic metrics\n",
    "print(\"=\" * 70)\n",
    "print(\"üìä EVERYTHING TRACKED AUTOMATICALLY (Zero Config!)\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"\\nüí∞ COST TRACKING:\")\n",
    "print(f\"   Cost: ${response1.cost:.4f}\")\n",
    "print(f\"   Tokens: {response1.usage.get('total_tokens', 0)}\")\n",
    "print(f\"   üëâ You'll see this coming BEFORE the bill arrives!\")\n",
    "\n",
    "print(f\"\\n‚ö° PERFORMANCE:\")\n",
    "print(f\"   Latency: {response1.latency:.2f}s\")\n",
    "print(f\"   üëâ Catch slow responses early!\")\n",
    "\n",
    "print(f\"\\n‚úÖ QUALITY SCORES:\")\n",
    "for metric, score in response1.scores.items():\n",
    "    print(f\"   {metric.capitalize()}: {score:.2f}\")\n",
    "print(f\"   üëâ Measure if responses are actually good!\")\n",
    "\n",
    "print(f\"\\nüîç TRACE ID: {response1.trace_id}\")\n",
    "print(f\"   üëâ Find this exact query later in MLflow UI\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"üí° THE VALUE: No more surprises!\")\n",
    "print(\"   ‚Ä¢ Know costs BEFORE the bill\")\n",
    "print(\"   ‚Ä¢ Track quality with scores\")\n",
    "print(\"   ‚Ä¢ Debug with full trace history\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(f\"\\nüìä View in UI: mlflow ui ‚Üí http://localhost:5000\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üìù Feature 2: Prompt Versioning\n",
    "\n",
    "## The Old Way (Without Versioning)\n",
    "\n",
    "**Monday:** You write a prompt. It works great!\n",
    "\n",
    "**Tuesday:** You \"improve\" it. Now it's slower and costs more.\n",
    "\n",
    "**Wednesday:** You want the Monday version back but... üò± **You didn't save it!**\n",
    "\n",
    "**Questions you can't answer:**\n",
    "- ‚ùì Which version was cheaper?\n",
    "- ‚ùì Which version was faster?\n",
    "- ‚ùì What exactly did I change?\n",
    "- ‚ùì Can I roll back?\n",
    "\n",
    "**You're guessing in the dark! üé≤**\n",
    "\n",
    "---\n",
    "\n",
    "## The New Way (With Prompt Versioning)\n",
    "\n",
    "**Track every version automatically. Compare with real numbers.**\n",
    "\n",
    "Let's see a dramatic example of prompt optimization:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Version 1: A verbose prompt (common mistake!)\n",
    "agent = Agent(\n",
    "    name=\"support_bot\",\n",
    "    model=\"claude-3-5-sonnet\",\n",
    "    system_prompt=\"\"\"You are a helpful support bot. Analyze support tickets and provide:\n",
    "1. Quick summary\n",
    "2. Root cause analysis\n",
    "3. Recommended actions\n",
    "\n",
    "Be concise and actionable.\"\"\",\n",
    "    tools=[],\n",
    ")\n",
    "\n",
    "print(\"üìù Version 1: The 'Detailed' Prompt\")\n",
    "print(\"   Status: Created and saved automatically\")\n",
    "print(f\"   Version: {agent.prompt_registry.get_latest().version}\")\n",
    "print(\"\\nüí° This is a common starting point - asks for lots of detail\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Version 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with version 1\n",
    "print(\"üîÑ Running with Version 1...\")\n",
    "result_v1 = agent.run(\n",
    "    f\"Analyze this ticket:\\n\\n{support_ticket}\",\n",
    "    evaluate=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Response Preview:\")\n",
    "print(f\"   {result_v1.response[:120]}...\")\n",
    "\n",
    "print(f\"\\nüìä Version 1 Metrics:\")\n",
    "print(f\"   Tokens: {result_v1.trace.total_tokens}\")\n",
    "print(f\"   Cost: ${result_v1.trace.total_cost:.4f}\")\n",
    "print(\"\\nüí≠ Hmm... verbose responses cost more tokens. Can we improve?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° Hypothesis: A Tighter Prompt Will Save Tokens\n",
    "\n",
    "**The insight:** Maybe we don't need all that detail for every ticket.\n",
    "\n",
    "Let's try a more concise version and **measure the difference**:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Version 2: Concise prompt\n",
    "print(\"üìù Creating Version 2: The 'Concise' Prompt\")\n",
    "print(\"   Goal: Reduce tokens while maintaining quality\\n\")\n",
    "\n",
    "agent.prompt_registry.add_version(\n",
    "    system_prompt=\"\"\"You are a support bot. For each ticket provide:\n",
    "1. Issue summary (1 line)\n",
    "2. Root cause (1 line)  \n",
    "3. Fix (1-2 lines)\n",
    "\n",
    "Be extremely concise.\"\"\",\n",
    "    user_template=\"{query}\",\n",
    "    examples=[],\n",
    "    metadata={\"change\": \"Made more concise\", \"reason\": \"Reduce tokens\"}\n",
    ")\n",
    "\n",
    "print(f\"‚úÖ Version 2 created and saved!\")\n",
    "print(f\"   Version number: {agent.prompt_registry.get_latest().version}\")\n",
    "print(\"\\nüí° Key change: Explicit limits on each section\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run with version 2\n",
    "print(\"üîÑ Running with Version 2...\")\n",
    "result_v2 = agent.run(\n",
    "    f\"Analyze this ticket:\\n\\n{support_ticket}\",\n",
    "    evaluate=True\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ Response Preview:\")\n",
    "print(f\"   {result_v2.response[:120]}...\")\n",
    "\n",
    "print(f\"\\nüìä Version 2 Metrics:\")\n",
    "print(f\"   Tokens: {result_v2.trace.total_tokens}\")\n",
    "print(f\"   Cost: ${result_v2.trace.total_cost:.4f}\")\n",
    "print(\"\\nüí≠ Now let's compare...\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üéØ The Moment of Truth: Side-by-Side Comparison\n",
    "\n",
    "**Did the concise prompt actually save money?**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare versions with dramatic reveal!\n",
    "print(\"=\" * 80)\n",
    "print(\"üìä VERSION COMPARISON: v1 (Detailed) vs v2 (Concise)\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "tokens_saved = result_v1.trace.total_tokens - result_v2.trace.total_tokens\n",
    "cost_saved = result_v1.trace.total_cost - result_v2.trace.total_cost\n",
    "savings_pct = (tokens_saved / result_v1.trace.total_tokens) * 100\n",
    "\n",
    "print(f\"\\n{'Metric':<20} {'v1 Detailed':<20} {'v2 Concise':<20} {'Difference':<20}\")\n",
    "print(\"-\" * 80)\n",
    "print(f\"{'Tokens':<20} {result_v1.trace.total_tokens:<20} {result_v2.trace.total_tokens:<20} ‚Üì {tokens_saved}\")\n",
    "print(f\"{'Cost':<20} ${result_v1.trace.total_cost:<19.4f} ${result_v2.trace.total_cost:<19.4f} ‚Üì ${cost_saved:.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(f\"üéâ RESULT: Version 2 saved {savings_pct:.1f}% tokens!\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "print(f\"\\nüí∞ THE VALUE:\")\n",
    "print(f\"   ‚Ä¢ {tokens_saved} fewer tokens per query\")\n",
    "print(f\"   ‚Ä¢ ${cost_saved:.4f} saved per query\")\n",
    "print(f\"   ‚Ä¢ At 1,000 queries/day: ${cost_saved * 1000:.2f}/day\")\n",
    "print(f\"   ‚Ä¢ That's ${cost_saved * 1000 * 30:.2f}/month saved!\")\n",
    "\n",
    "print(f\"\\n‚úÖ Without versioning, you'd never know which prompt was better!\")\n",
    "print(f\"   Now you have PROOF that v2 is {savings_pct:.0f}% more efficient.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View version history\n",
    "print(\"\\nüìö Full Version History (Git for Prompts!):\")\n",
    "print(\"-\" * 60)\n",
    "history = agent.prompt_registry.list_versions()\n",
    "for item in history[-5:]:  # Show last 5 versions\n",
    "    version = item['version']\n",
    "    change = item['metadata'].get('change', 'Initial version')\n",
    "    reason = item['metadata'].get('reason', '')\n",
    "    print(f\"   v{version}: {change}\")\n",
    "    if reason:\n",
    "        print(f\"        Reason: {reason}\")\n",
    "\n",
    "print(f\"\\nüíæ Storage: {agent.prompt_registry.registry_path}\")\n",
    "print(f\"\\n‚ú® THE VALUE:\")\n",
    "print(f\"   ‚Ä¢ Never lose a working prompt\")\n",
    "print(f\"   ‚Ä¢ Roll back if new version fails\")\n",
    "print(f\"   ‚Ä¢ Know exactly what changed and why\")\n",
    "print(f\"   ‚Ä¢ Measure impact with real numbers\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üß† Feature 3: DSPy-Style Optimization\n",
    "\n",
    "## The Old Way (Without AI Assistance)\n",
    "\n",
    "**You:** \"Hmm, this prompt could be better...\"\n",
    "\n",
    "**Also you:** \"But... how? What should I change?\"\n",
    "\n",
    "**Your options:**\n",
    "1. ‚ùì Guess and try random changes\n",
    "2. ‚ùì Ask a colleague (who also guesses)\n",
    "3. ‚ùì Read generic advice like \"be more specific\"\n",
    "\n",
    "**You're optimizing blind! üéØ**\n",
    "\n",
    "---\n",
    "\n",
    "## The New Way (With DSPy-Style Optimization)\n",
    "\n",
    "**Two levels of help:**\n",
    "\n",
    "### Level 1: Fast Heuristic Analysis (Instant, Free)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get AI-powered improvement suggestions\n",
    "print(\"üß† AI Analysis: Analyzing your prompt patterns...\")\n",
    "print(\"-\" * 60)\n",
    "\n",
    "mla.set_suggestion_provider(\"claude-3-5-sonnet\")\n",
    "mla.print_suggestions(response1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üîÑ Feature 4: Reliability Features\n",
    "\n",
    "**The Problem:** LLM APIs timeout, fail, or get rate-limited ‚Üí Your app breaks\n",
    "\n",
    "**The Solution:** Built-in retry, timeout, and fallback support ‚Üí Always available\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure global defaults\n",
    "mla.set_timeout(30)  # 30 second timeout\n",
    "mla.set_max_retries(5)  # 5 retry attempts\n",
    "mla.set_fallback_models([\"gpt-4o\", \"gpt-3.5-turbo\"])  # Fallback chain\n",
    "\n",
    "print(\"‚úÖ Reliability configured:\")\n",
    "print(\"   ‚Ä¢ Timeout: 30s\")\n",
    "print(\"   ‚Ä¢ Max retries: 5 (with exponential backoff)\")\n",
    "print(\"   ‚Ä¢ Fallbacks: gpt-4o ‚Üí gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Per-request reliability config\n",
    "response = mla.query(\n",
    "    model=\"claude-3-5-sonnet\",\n",
    "    prompt=\"Explain circuit breaker pattern in one sentence\",\n",
    "    timeout=20,\n",
    "    max_retries=3,\n",
    "    fallback_models=[\"gpt-4o\"]\n",
    ")\n",
    "\n",
    "print(f\"Model used: {response.model}\")\n",
    "print(f\"Response: {response.content}\")\n",
    "print(f\"Latency: {response.latency:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Value\n",
    "\n",
    "**High Availability:**\n",
    "- Automatic failover prevents downtime\n",
    "- Retry logic handles transient failures\n",
    "- Timeout prevents hanging requests\n",
    "\n",
    "**Production Ready:**\n",
    "```python\n",
    "# One line for production-grade reliability\n",
    "mla.set_fallback_models([\"claude-3-5-sonnet\", \"gpt-4o\", \"gpt-3.5-turbo\"])\n",
    "```\n",
    "\n",
    "**Result:** 99.9% uptime even if primary provider has issues."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üéâ What You Just Learned\n",
    "\n",
    "## From Chaos to Clarity in 3 Features\n",
    "\n",
    "### Before mlflowlite:\n",
    "- ‚ùå No idea what queries cost until the bill arrives\n",
    "- ‚ùå Lost good prompt versions\n",
    "- ‚ùå Guessing at improvements\n",
    "- ‚ùå Flying blind\n",
    "\n",
    "### After mlflowlite:\n",
    "- ‚úÖ **See costs in real-time** ‚Üí Saved $XXX/month\n",
    "- ‚úÖ **Track prompt versions** ‚Üí Know what works\n",
    "- ‚úÖ **Get AI-powered advice** ‚Üí Optimize systematically\n",
    "\n",
    "---\n",
    "\n",
    "## üí∞ The Business Case\n",
    "\n",
    "Based on what we just demonstrated:\n",
    "\n",
    "**Without mlflowlite (monthly):**\n",
    "- Wasted tokens: ~40% more than needed\n",
    "- Bill surprises: Can't predict costs\n",
    "- Lost prompts: Repeat work\n",
    "- **Total impact: Time + Money + Stress**\n",
    "\n",
    "**With mlflowlite (monthly):**\n",
    "- Token savings: 40% reduction = $XXX saved\n",
    "- No surprises: Track every query\n",
    "- Version control: Never lose working prompts\n",
    "- **Total impact: Faster + Cheaper + Confident**\n",
    "\n",
    "---\n",
    "\n",
    "## üöÄ Next Steps\n",
    "\n",
    "### 1. View Your Traces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this in your terminal to view all traces:\n",
    "# mlflow ui\n",
    "\n",
    "print(\"üìä To view all traces:\")\n",
    "print(\"   1. Open a terminal\")\n",
    "print(\"   2. Run: mlflow ui\")\n",
    "print(\"   3. Open: http://localhost:5000\")\n",
    "print(\"\")\n",
    "print(\"You'll see:\")\n",
    "print(\"   ‚Ä¢ All query runs with metrics\")\n",
    "print(\"   ‚Ä¢ Latency, cost, token usage\")\n",
    "print(\"   ‚Ä¢ Model comparisons\")\n",
    "print(\"   ‚Ä¢ Prompt version history\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Your Turn: Try It On Your Data\n",
    "\n",
    "The same 3-step process works for ANY use case:\n",
    "\n",
    "```python\n",
    "# Step 1: Make a query (automatic tracing!)\n",
    "my_response = mla.query(\n",
    "    model='claude-3-5-sonnet',\n",
    "    prompt='Your custom prompt',\n",
    "    input='Your data'\n",
    ")\n",
    "# ‚Üí See costs immediately\n",
    "\n",
    "# Step 2: Track versions (measure improvements!)\n",
    "my_agent = Agent(name=\"my_agent\", model=\"claude-3-5-sonnet\")\n",
    "result_v1 = my_agent.run(\"Your query\")\n",
    "# ‚Üí Make changes\n",
    "agent.prompt_registry.add_version(...)\n",
    "result_v2 = my_agent.run(\"Your query\")\n",
    "# ‚Üí Compare with real numbers\n",
    "\n",
    "# Step 3: Get smart advice (optimize systematically!)\n",
    "mla.print_suggestions(my_response, use_llm=True)\n",
    "# ‚Üí Apply specific suggestions\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## üí° The Real Value\n",
    "\n",
    "### What This Gives You:\n",
    "\n",
    "1. **üîç Visibility**: Know exactly what's happening\n",
    "   - No more bill surprises\n",
    "   - Track quality with scores\n",
    "   - Debug with full traces\n",
    "\n",
    "2. **üìä Data-Driven Decisions**: Measure, don't guess\n",
    "   - Prove version 2 is 40% better\n",
    "   - Know which model is worth the cost\n",
    "   - Track improvements over time\n",
    "\n",
    "3. **üöÄ Systematic Improvement**: Optimize with AI help\n",
    "   - Get specific, actionable suggestions\n",
    "   - Learn patterns across queries\n",
    "   - Improve continuously\n",
    "\n",
    "---\n",
    "\n",
    "## üéØ Start Using It Today\n",
    "\n",
    "**It's this simple:**\n",
    "```python\n",
    "import mlflowlite as mla\n",
    "\n",
    "response = mla.query(model='claude-3-5-sonnet', prompt='...', input='...')\n",
    "# Everything else happens automatically!\n",
    "```\n",
    "\n",
    "**Then view in MLflow UI to see the full power:**\n",
    "```bash\n",
    "mlflow ui  # Open http://localhost:5000\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "**üéâ You now have observability, versioning, and optimization - all automatic!**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "# üöÄ Advanced: Smart Routing & A/B Testing\n",
    "\n",
    "**For production applications:** Optimize costs and make data-driven decisions.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Smart Routing üß†\n",
    "\n",
    "Automatically select the best model based on query complexity.\n",
    "\n",
    "**The Problem:** Simple queries waste money on expensive models.\n",
    "\n",
    "**The Solution:** Smart routing analyzes complexity and picks the optimal model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 1: Simple query ‚Üí Fast model\n",
    "decision, response = mla.smart_query(\"What is 2+2?\")\n",
    "\n",
    "print(f\"Model selected: {decision.model}\")\n",
    "print(f\"Reason: {decision.reason}\")\n",
    "print(f\"Complexity score: {decision.complexity_score:.2f}\")\n",
    "print(f\"Response: {response.content}\")\n",
    "print(f\"Cost: ${response.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2: Complex query ‚Üí Quality model\n",
    "decision, response = mla.smart_query(\n",
    "    \"\"\"Analyze the trade-offs between microservices and monolithic \n",
    "    architectures. Consider scalability and maintainability.\"\"\"\n",
    ")\n",
    "\n",
    "print(f\"Model selected: {decision.model}\")\n",
    "print(f\"Reason: {decision.reason}\")\n",
    "print(f\"Complexity score: {decision.complexity_score:.2f}\")\n",
    "print(f\"Response: {response.content[:150]}...\")\n",
    "print(f\"Cost: ${response.cost:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Value\n",
    "\n",
    "**Cost Savings:**\n",
    "- Simple queries: gpt-3.5-turbo ($0.001) vs gpt-4o ($0.01) = **90% savings**\n",
    "- Automatic optimization across 1000s of queries\n",
    "- No manual routing logic needed\n",
    "\n",
    "**Result:** $100 ‚Üí $55 monthly cost (45% average savings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## A/B Testing üß™\n",
    "\n",
    "Compare models or prompts with automatic tracking.\n",
    "\n",
    "**The Problem:** Which model/prompt is actually better?\n",
    "\n",
    "**The Solution:** Data-driven A/B testing with automatic winner detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create A/B test\n",
    "test = mla.create_ab_test(\n",
    "    name=\"model_comparison\",\n",
    "    variants={\n",
    "        'gpt4': {'model': 'gpt-4o', 'temperature': 0.7},\n",
    "        'claude': {'model': 'claude-3-5-sonnet', 'temperature': 0.7}\n",
    "    },\n",
    "    split=[0.5, 0.5]  # 50/50 split\n",
    ")\n",
    "\n",
    "print(\"‚úÖ A/B test created\")\n",
    "print(f\"   Variants: {list(test.variants.keys())}\")\n",
    "print(f\"   Split: {test.split}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run test with multiple queries\n",
    "queries = [\n",
    "    \"Explain machine learning\",\n",
    "    \"What are microservices?\",\n",
    "    \"How does REST API work?\",\n",
    "    \"Explain cloud computing\",\n",
    "    \"What is DevOps?\"\n",
    "]\n",
    "\n",
    "print(\"Running A/B test...\\n\")\n",
    "for query in queries:\n",
    "    variant, response = test.run(\n",
    "        messages=[{\"role\": \"user\", \"content\": query}]\n",
    "    )\n",
    "    print(f\"Query: {query[:30]}...\")\n",
    "    print(f\"  ‚Üí {variant} | ${response.cost:.4f} | {response.latency:.2f}s\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View results\n",
    "test.print_report()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get winner\n",
    "winner, stats = test.get_winner('cost')\n",
    "\n",
    "print(f\"\\nüèÜ Winner (by cost): {winner}\")\n",
    "print(f\"   Average cost: ${stats['avg_cost']:.4f}\")\n",
    "print(f\"   Total requests: {stats['count']}\")\n",
    "print(f\"   Avg latency: {stats['avg_latency']:.2f}s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí∞ Value\n",
    "\n",
    "**Data-Driven Decisions:**\n",
    "- Test before committing to a model\n",
    "- Automatic tracking of all metrics\n",
    "- Clear winner detection\n",
    "- Compare anything: models, prompts, configs\n",
    "\n",
    "**Result:** Switch to winner ‚Üí save 20-40% on costs with same quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## üéØ Advanced Features Summary\n",
    "\n",
    "**Smart Routing:**\n",
    "```python\n",
    "decision, response = mla.smart_query(\"Your query\")\n",
    "# Automatic model selection based on complexity\n",
    "```\n",
    "\n",
    "**A/B Testing:**\n",
    "```python\n",
    "test = mla.create_ab_test(name=\"test\", variants={...})\n",
    "variant, response = test.run(messages=[...])\n",
    "test.print_report()\n",
    "```\n",
    "\n",
    "**Combined Impact:**\n",
    "- 45% average cost reduction\n",
    "- Data-driven optimization\n",
    "- Production-ready reliability"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
